{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "   raise ValueError('GEMINI_API_KEY is not set in the env file')\n",
    "print('GEMINI_API_KEY loaded successfully')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import display,Markdown\n",
    "llm = ChatGoogleGenerativeAI(api_key=GEMINI_API_KEY,temperature=0,model='gemini-1.5-flash')\n",
    "resp = llm.invoke('what is the meaning of life?') \n",
    "display(Markdown(resp.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "import json\n",
    "from IPython.display import display,Image\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import requests\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from IPython.display import display,Markdown\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "   raise ValueError('GEMINI_API_KEY is not set in the env file')\n",
    "print('GEMINI_API_KEY loaded successfully')    \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(api_key=GEMINI_API_KEY,temperature=0,model='gemini-1.5-flash')\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    story_theme: str\n",
    "    generated_story: str\n",
    "    character_list:str\n",
    "    plot:list[str]\n",
    "    image_prompts: list[str] \n",
    "    voice_saved_path:str    \n",
    "    image_saved_path:str\n",
    "    \n",
    "def generate_story(state:GraphState)->GraphState:\n",
    "    story_theme = state['story_theme']\n",
    "    generate_story_prompt =\"\"\"\n",
    "    Imagine you are a skilled storyteller tasked with creating a simple and interesting story based on the theme below.  \n",
    "  \n",
    "    Theme: {theme}\n",
    "    Your goal is to generate a detailed and realistic story\n",
    "    The story should have:\n",
    "    - A clear beginning, middle, and end.\n",
    "    - Easy-to-understand language.\n",
    "    - Detail and meaningful sentences.\n",
    "    - Interesting characters and events.\n",
    "    \n",
    "    Story:\n",
    "    \"\"\"\n",
    "    sys_msg = SystemMessage(content=\"You are a storyteller who writes clear and engaging stories in simple English.\")\n",
    "    hum_msg =  HumanMessage(content=generate_story_prompt.format(theme=story_theme))\n",
    "    print('Generating story for theme')\n",
    "    resp = llm.invoke([sys_msg,hum_msg])\n",
    "    state['generated_story'] = resp.content\n",
    "    return state \n",
    "def generate_story_char(state:GraphState)->GraphState:\n",
    "    story = state['generated_story'] \n",
    "    generate_description_prompt = '''Based on the Story {story}, create a brief description of the main and supporting character, object, or scene. Include specific details about appearance, characteristics, and any unique features. This description will be used to maintain consistency across multiple images.'''\n",
    "    sys_msg = SystemMessage(content=\"You are an assistant that extracts all character names and details from a story.\")\n",
    "    hum_msg =  HumanMessage(content=generate_description_prompt.format(story=story))\n",
    "    print('Generating story Characters')\n",
    "    resp = llm.invoke([sys_msg,hum_msg])\n",
    "    state['character_list'] = resp.content\n",
    "    return state\n",
    "\n",
    "def generate_plot(state: GraphState) -> GraphState:\n",
    "    story = state['generated_story']\n",
    "    character_description =  state['character_list']\n",
    "    generate_description_prompt = f\"\"\"create a short, 5-step plot for a video based on this story: '{story}' and featuring this description: {character_description}. Each step should be a brief description of a single frame, maintaining consistency throughout. Keep it family-friendly and avoid any sensitive themes.\n",
    "      ....\n",
    "\n",
    "    Return the plot as a in JSON, formatted as follows:\n",
    "    [\"Step 1 description\", \"Step 2 description\", \"Step 3 description\", \"Step 4 description\", \"Step 5 description\"]\n",
    "    \"\"\"\n",
    "    hum_msg = HumanMessage(content=generate_description_prompt.format(story=story,character_description=character_description))\n",
    "    print('Generating scene description of the story')\n",
    "    resp = llm.invoke([hum_msg]) \n",
    "    plot_string = resp.content\n",
    "    json_string = plot_string.strip().replace('```json', '').replace('```', '').strip()\n",
    "    plot_list = json.loads(json_string)\n",
    "    state['plot']=plot_list\n",
    "    return state \n",
    "def generate_image_prompts(state: GraphState) -> GraphState:\n",
    "    plot =  state['plot']\n",
    "    character_description =  state['character_list']\n",
    "    generate_description_prompt = f\"\"\"Based on this plot: '{plot}' and featuring this description: {character_description}, generate 5 specific, family-friendly image prompts, one for each step. Each prompt should be detailed enough for image generation, maintaining consistency, and suitable for DALL-E. \n",
    "\n",
    "                                    Always include the following in EVERY prompt to maintain consistency:\n",
    "                                    1. A brief reminder of the main character or object's key features\n",
    "                                    2. The specific action or scene described in the plot step\n",
    "                                    3. Any relevant background or environmental details\n",
    "\n",
    "                                    Format each prompt as a numbered list item, like this:\n",
    "                                    1. [Your prompt here]\n",
    "                                    2. [Your prompt here]\n",
    "                                    ... and so on.\n",
    "                                        \"\"\"\n",
    "    \n",
    "\n",
    "    hum_msg = HumanMessage(content=generate_description_prompt.format(character_description=character_description, plot=plot))\n",
    "    print('Generating image prompts for the story')\n",
    "    response = llm.invoke([hum_msg])\n",
    "    prompts = []\n",
    "    for line in response.content.split(\"\\n\"):\n",
    "        if line.strip().startswith((\"1.\", \"2.\", \"3.\", \"4.\", \"5.\")):\n",
    "            prompt = line.split(\".\", 1)[1].strip()\n",
    "            prompts.append(\n",
    "                f\"Create a detailed, photorealistic image of the following scene: {prompt}\"\n",
    "            )\n",
    "\n",
    "    if len(prompts) != 5:\n",
    "        raise ValueError(\n",
    "            f\"Expected 5 prompts, but got {len(prompts)}. Please try again.\"\n",
    "        )\n",
    "\n",
    "    state[\"image_prompts\"] = prompts\n",
    "    return state\n",
    "\n",
    "def voice_generates(text: str, file_name: str, folder: str):\n",
    "    try:\n",
    "        tts = gTTS(text)\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        save_path = os.path.join(folder, file_name)\n",
    "        tts.save(save_path)\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def finalvoicefun(sceneList):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    dynamic_folder_voice = f\"voice_{timestamp}\"\n",
    "    output_folder_voice = os.path.join(\"Generated_voice\", dynamic_folder_voice)\n",
    "    voice_paths = []\n",
    "    for i, scene in enumerate(sceneList):\n",
    "        try:\n",
    "            voice_path = voice_generates(\n",
    "                scene, f\"voice_scene_{i+1}.mp3\", output_folder_voice\n",
    "            )\n",
    "\n",
    "            if voice_path:\n",
    "                voice_paths.append(voice_path)\n",
    "                print(f\"Voiceover saved locally: {voice_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to save voiceover for scene {i+1}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating voice for scene {i+1}: {e}\")\n",
    "    return output_folder_voice    \n",
    "\n",
    "def generate_scence_voice(state:GraphState)->GraphState:\n",
    "    scene_list = state['plot']\n",
    "    resp = finalvoicefun(scene_list) \n",
    "    print(f\"Generating voice{resp}\")\n",
    "    return {'voice_saved_path':resp}\n",
    "    # state['voice_saved_path'] = resp\n",
    "    # return state\n",
    "\n",
    "def saveImage(image_content, save_path):\n",
    "    output_folder = os.path.dirname(save_path)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(image_content)\n",
    "\n",
    "\n",
    "def images_generates(prompt: str):\n",
    "    try:\n",
    "        # response = client.images.generate(\n",
    "        #     model=imagemodel,\n",
    "        #     prompt=prompt,\n",
    "        #     quality=\"standard\",\n",
    "        #     n=1,\n",
    "        # )\n",
    "        # image_url = response.data[0].url\n",
    "        image_url = \"https://www.w3schools.com/w3images/lights.jpg\"\n",
    "        return image_url\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error generating image: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def finalscenesfun(image_prompts):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    dynamic_folder = f\"images_{timestamp}\"\n",
    "    output_folder = os.path.join(\"Generated_images\", dynamic_folder)\n",
    "\n",
    "    for i, scene in enumerate(image_prompts):\n",
    "        try:\n",
    "             \n",
    "            imageUrl = images_generates(scene)\n",
    "            if not imageUrl:\n",
    "                raise ValueError(\"Generated image URL is empty.\")\n",
    "\n",
    "            imageContent = requests.get(imageUrl).content\n",
    "            if not imageContent:\n",
    "                raise ValueError(\"Failed to retrieve image content.\")\n",
    "\n",
    "            save_path = os.path.join(output_folder, f\"image_scene_{i+1}.png\")\n",
    "            saveImage(imageContent, save_path)\n",
    "            print(f\"Images saved to {save_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing scene {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return output_folder\n",
    "\n",
    "def generate_scence_image(state:GraphState)->GraphState:\n",
    "    image_prompts = state['image_prompts']\n",
    "    resp = finalscenesfun(image_prompts) \n",
    "    state[\"image_saved_path\"]=resp\n",
    "    print(f\"Generating images path: {resp}\")\n",
    "    return {\"image_saved_path\": resp}\n",
    "    # state['image_saved_path'] = resp\n",
    "    # return state\n",
    "\n",
    "def final_video(state:GraphState)->GraphState:\n",
    "   \n",
    "    return state\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_story',generate_story)\n",
    "workflow.add_node('generate_story_char',generate_story_char)\n",
    "workflow.add_node('generate_plot',generate_plot)\n",
    "workflow.add_node('generate_image_prompts',generate_image_prompts)\n",
    "workflow.add_node('generate_scence_voice',generate_scence_voice)\n",
    "workflow.add_node('generate_scence_image',generate_scence_image)\n",
    "workflow.add_node('final_video',final_video)\n",
    "\n",
    "workflow.add_edge(START,'generate_story')\n",
    "workflow.add_edge('generate_story','generate_story_char')\n",
    "workflow.add_edge('generate_story_char','generate_plot')\n",
    "workflow.add_edge('generate_plot','generate_image_prompts')\n",
    "workflow.add_edge('generate_plot','generate_scence_voice')\n",
    "workflow.add_edge('generate_image_prompts','generate_scence_image')\n",
    " \n",
    "workflow.add_edge(['generate_scence_voice','generate_scence_image'],'final_video') \n",
    "workflow.add_edge('final_video',END) \n",
    "\n",
    "app = workflow.compile()\n",
    "# display(Image(app.get_graph().draw_mermaid_png()))\n",
    "story_theme =  \"\"\"A 24 year old boy seeing out from the train’s window shouted…\n",
    "\n",
    "“Dad, look the trees are going behind!”\n",
    "\n",
    "Dad smiled and a young couple sitting nearby, looked at the 24 year old’s childish behavior with pity, suddenly he again exclaimed…\n",
    "\n",
    "“Dad, look the clouds are running with us!”\n",
    "\n",
    "The couple couldn’t resist and said to the old man…\n",
    "\n",
    "“Why don’t you take your son to a good doctor?” The old man smiled and said…“I did and we are just coming from the hospital, my son was blind from birth, he just got his eyes today.”\n",
    "\n",
    "Every single person on the planet has a story. Don’t judge people before you truly know them. The truth might surprise you.\"\"\"\n",
    "resp = app.invoke({'story_theme':story_theme})\n",
    "print(resp)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp['image_prompts'][4\n",
    "                    ])  \n",
    "print('hi')  \n",
    "   \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, base64\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEYs\")\n",
    "if not NVIDIA_API_KEY:\n",
    "   raise ValueError('NVIDIA_API_KEY is not set in the env file')\n",
    "print('NVIDIA_API_KEY loaded successfully')   \n",
    "invoke_url = \"https://ai.api.nvidia.com/v1/genai/nvidia/consistory\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NVIDIA_API_KEY}\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"mode\": 'init',\n",
    "    \"subject_prompt\": \"A 24-year-old man with wide, curious eyes, experiencing sight for the first time.\",\n",
    "    \"subject_tokens\":[\"man\", \"curly hair\", \"glasses\", \"blue jacket\"],\n",
    "    \"subject_seed\": 24,\n",
    "    \"style_prompt\": \"A highly detailed photorealistic portrait\",\n",
    "    \"scene_prompt1\": \"Leo pressing his face against a cool train window, excitedly pointing at the passing landscape.\",\n",
    "    \"negative_prompt\": \"blurry, distorted, unrealistic\",\n",
    "    \"cfg_scale\": 5,\n",
    "    \"same_initial_noise\": False,\n",
    "    \"image_width\": 1080,  # Set width for Shorts\n",
    "    \"image_height\": 1920,  # Set height for Shorts\n",
    "}\n",
    "\n",
    "response = requests.post(invoke_url, headers=headers, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "for idx, img_data in enumerate(data['artifacts']):\n",
    "  img_base64 = img_data[\"base64\"]\n",
    "  img_bytes = base64.b64decode(img_base64)\n",
    "  with open(f'{idx}.jpg', \"wb\") as f:\n",
    "      f.write(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, base64\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\")\n",
    "if not NVIDIA_API_KEY:\n",
    "   raise ValueError('NVIDIA_API_KEY is not set in the env file')\n",
    "print('NVIDIA_API_KEY loaded successfully')   \n",
    "invoke_url = \"https://ai.api.nvidia.com/v1/genai/nvidia/consistory\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {NVIDIA_API_KEY}\",\n",
    "    \"Accept\": \"application/json\",\n",
    "}\n",
    "\n",
    " \n",
    "payload = {\n",
    "    \"mode\": 'init',\n",
    "    \"subject_prompt\": \"A 24-year-old man with wide, curious eyes, experiencing sight for the first time.\",\n",
    "    \"subject_tokens\":[\"man\", \"curly hair\", \"glasses\", \"blue jacket\"],\n",
    "    \"subject_seed\": 43,\n",
    "    \"style_prompt\": \"A highly detailed photorealistic portrait\",\n",
    "    \"scene_prompt1\": \"Leo pressing his face against a cool train window, excitedly pointing at the passing landscape.\",\n",
    "    \"negative_prompt\": \"blurry, distorted, unrealistic\",\n",
    "    \"cfg_scale\": 5,\n",
    "    \"same_initial_noise\": False,\n",
    " \n",
    "}\n",
    "\n",
    "response = requests.post(invoke_url, headers=headers, json=payload)\n",
    "response.raise_for_status()\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "for idx, img_data in enumerate(data['artifacts']):\n",
    "  img_base64 = img_data[\"base64\"]\n",
    "  img_bytes = base64.b64decode(img_base64)\n",
    "  with open(f'{idx}.jpg', \"wb\") as f:\n",
    "      f.write(img_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    story_theme: str\n",
    "    generated_story: str\n",
    "    \n",
    "def generate_story(state:GraphState)->GraphState:\n",
    "    story_theme = state['story_theme']\n",
    "    generate_story_prompt =\"\"\"\n",
    "    Imagine you are a skilled storyteller tasked with creating a simple and interesting story based on the theme below.  \n",
    "  \n",
    "    Theme: {theme}\n",
    "    Your goal is to generate a detailed and realistic story\n",
    "    The story should have:\n",
    "    - A clear beginning, middle, and end.\n",
    "    - Easy-to-understand language.\n",
    "    - Detail and meaningful sentences.\n",
    "    - Interesting characters and events.\n",
    "    \n",
    "    Story:\n",
    "    \"\"\"\n",
    "    sys_msg = SystemMessage(content=\"You are a storyteller who writes clear and engaging stories in simple English.\")\n",
    "    hum_msg =  HumanMessage(content=generate_story_prompt.format(theme=story_theme))\n",
    "    resp = llm.invoke([sys_msg,hum_msg])\n",
    "    state['generated_story'] = resp.content\n",
    "    return state \n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_story',generate_story)\n",
    "workflow.add_edge(START,'generate_story')\n",
    "workflow.add_edge('generate_story',END)\n",
    "app = workflow.compile()\n",
    "\n",
    "story_theme =  \"Once upon a time, there was a boy who lived in a jungle. One day, he saw a lion cub that was very hungry. The boy gave food to the lion cub, and they became friends.\"\n",
    "resp = app.invoke({'story_theme':story_theme})\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    story: str\n",
    "    charlist: list\n",
    "    \n",
    "def generate_story_char(state:GraphState)->GraphState:\n",
    "    story = state['story'] \n",
    "    generate_description_prompt = '''Based on the Story {story}, create a brief description of the main and supporting character, object, or scene. Include specific details about appearance, characteristics, and any unique features. This description will be used to maintain consistency across multiple images.'''\n",
    " \n",
    "    sys_msg = SystemMessage(content=\"You are an assistant that extracts all character names and details from a story.\")\n",
    "    hum_msg =  HumanMessage(content=generate_description_prompt.format(story=story))\n",
    "    resp = llm.invoke([sys_msg,hum_msg])\n",
    "    state['charlist'] = resp.content\n",
    "    return state \n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_story_char',generate_story_char)\n",
    "workflow.add_edge(START,'generate_story_char')\n",
    "workflow.add_edge('generate_story_char',END)\n",
    "app = workflow.compile()\n",
    "\n",
    "story =  \"\"\"Once upon a time, deep in a lush green jungle, lived a boy named Mika. Mika wasn't like the other children in his village. While they played near their homes, Mika loved exploring the jungle, its secrets whispering to him in the rustling leaves and the calls of unseen birds. He knew the paths like the back of his hand, and the jungle felt like a second home.\n",
    "\n",
    "One sweltering afternoon, while searching for juicy mangoes, Mika stumbled upon a tiny lion cub, huddled under a giant banyan tree. The cub was thin, its ribs showing through its tawny fur. Its eyes, usually bright and playful, were dull with hunger. A whimper escaped its tiny mouth. Mika’s heart ached. He knew what hunger felt like; sometimes his family didn't have enough to eat.\n",
    "\n",
    "Carefully, Mika approached the cub. He offered it a half-eaten mango, holding it out gently in his palm. The cub, hesitant at first, sniffed the fruit cautiously before lapping at the sweet juice. Mika smiled. He shared the rest of his mangoes with the cub, and then, remembering the sweet potatoes his mother had packed for him, he offered those too. The cub ate greedily, its tail thumping weakly against the ground.\n",
    "\n",
    "Day after day, Mika visited the cub, bringing it food he found or shared from his own meals. He named the cub Leo. Slowly, Leo grew stronger, his fur regaining its shine, his eyes sparkling with life. They played together, Mika chasing Leo through the undergrowth, Leo playfully batting at Mika's legs. A unique friendship blossomed between a boy and a lion cub, a bond forged in shared hunger and kindness.\n",
    "\n",
    "One day, Mika’s father saw him playing with Leo. He was worried at first, but Mika explained their friendship. To his surprise, his father understood. He knew the jungle was full of wonders, and that sometimes, the greatest friendships came from the most unexpected places. Mika and Leo continued their adventures, their bond a testament to the power of kindness and the magic of the jungle. And so, the boy who lived in the jungle and his lion cub friend lived happily, their story whispered on the jungle breeze.\"\"\"\n",
    "resp = app.invoke({'story':story})\n",
    "print(resp['charlist'])\n",
    "print(type(resp['charlist']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import ast\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import json\n",
    "class GraphState(TypedDict):\n",
    "    story: str\n",
    "    plot: list[str]   \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def generate_plot(state: GraphState) -> GraphState:\n",
    "    story = state['story']\n",
    "    character_description = \"\"\"**Main Characters:**\n",
    "\n",
    "    * **Mika:** A boy who lives in a lush green jungle. He is adventurous, kind, and resourceful, possessing intimate knowledge of the jungle's secrets.  He is depicted as having a compassionate heart, evident in his care for Leo.  No specific physical description is given.\n",
    "\n",
    "    * **Leo:** A tiny lion cub, initially weak and undernourished, with thin, dusty fur and dull eyes. As he recovers, his fur becomes thicker and shinier, and his eyes sparkle with playful energy.\n",
    "\n",
    "    * **Leo's Mother:** A large lioness with a magnificent mane.  She is depicted as cautious but ultimately grateful and understanding of Mika's kindness.\n",
    "\n",
    "\n",
    "    **Supporting Characters/Elements:**\n",
    "\n",
    "    * **Monkeys:**  Inhabit the jungle trees and are Mika's friends. No specific details are given about their appearance.\n",
    "\n",
    "    * **Rhinoceroses:** Described as \"grumpy\" and inhabiting the jungle. No specific details are given about their appearance.\n",
    "\n",
    "    * **Banyan Tree:** A large tree where Mika finds the lion cub.\n",
    "\n",
    "    **Objects:**\n",
    "\n",
    "    * **Mangoes:** Juicy mangoes that Mika shares with Leo.\n",
    "\n",
    "    * **Berries:**  Food collected by Mika and shared with Leo.\n",
    "    ...\n",
    "    * **Banyan Tree Scene:** The scene where Mika discovers the weak lion cub under the banyan tree.\n",
    "\n",
    "    * **Final Scene:** Mika observes Leo and his mother together, thriving in the jungle.\"\"\"\n",
    "    generate_description_prompt = f\"\"\"create a short, 5-step plot for a video based on this story: '{story}' and featuring this description: {character_description}. Each step should be a brief description of a single frame, maintaining consistency throughout. Keep it family-friendly and avoid any sensitive themes.\n",
    "      ....\n",
    "\n",
    "    Return the plot as a in JSON, formatted as follows:\n",
    "    [\"Step 1 description\", \"Step 2 description\", \"Step 3 description\", \"Step 4 description\", \"Step 5 description\"]\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    hum_msg = HumanMessage(content=generate_description_prompt.format(story=story,character_description=character_description))\n",
    "    resp = llm.invoke([hum_msg])\n",
    "\n",
    "    # Parse the LLM's response into a list of strings\n",
    "    plot_string = resp.content\n",
    "    json_string = plot_string.strip().replace('```json', '').replace('```', '').strip()\n",
    "    plot_list = json.loads(json_string)\n",
    "    state['plot']=plot_list\n",
    "    return state \n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_plot', generate_plot)\n",
    "workflow.add_edge(START, 'generate_plot')\n",
    "workflow.add_edge('generate_plot', END)\n",
    "app = workflow.compile()\n",
    "\n",
    "story = \"\"\"Once upon a time, deep in a lush green jungle, lived a boy named Mika. Mika wasn't like the other children in his village. While they played near their homes, Mika loved exploring the jungle, its secrets whispering to him in the rustling leaves and the calls of unseen birds. He knew the paths like the back of his hand, and the jungle felt like a second home.\n",
    "\n",
    "One sweltering afternoon, while searching for juicy mangoes, Mika stumbled upon a tiny lion cub, huddled under a giant banyan tree. The cub was thin, its ribs showing through its tawny fur. Its eyes, usually bright and playful, were dull with hunger. A whimper escaped its tiny mouth. Mika’s heart ached. He knew what hunger felt like; sometimes his family didn't have enough to eat.\n",
    "\n",
    "Carefully, Mika approached the cub. He offered it a half-eaten mango, holding it out gently in his palm. The cub, hesitant at first, sniffed the fruit cautiously before lapping at the sweet juice. Mika smiled. He shared the rest of his mangoes with the cub, and then, remembering the sweet potatoes his mother had packed for him, he offered those too. The cub ate greedily, its tail thumping weakly against the ground.\n",
    "\n",
    "Day after day, Mika visited the cub, bringing it food he found or shared from his own meals. He named the cub Leo. Slowly, Leo grew stronger, his fur regaining its shine, his eyes sparkling with life. They played together, Mika chasing Leo through the undergrowth, Leo playfully batting at Mika's legs. A unique friendship blossomed between a boy and a lion cub, a bond forged in shared hunger and kindness.\n",
    "\n",
    "One day, Mika’s father saw him playing with Leo. He was worried at first, but Mika explained their friendship. To his surprise, his father understood. He knew the jungle was full of wonders, and that sometimes, the greatest friendships came from the most unexpected places. Mika and Leo continued their adventures, their bond a testament to the power of kindness and the magic of the jungle. And so, the boy who lived in the jungle and his lion cub friend lived happily, their story whispered on the jungle breeze.\"\"\"\n",
    "\n",
    "resp = app.invoke({'story': story})\n",
    "print(resp['plot'])\n",
    "print(type(resp['plot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import ast\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import json\n",
    "class GraphState(TypedDict):\n",
    "    story: str\n",
    "    plot: list[str]  \n",
    "    image_prompts: list[str] \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "def generate_plot(state: GraphState) -> GraphState:\n",
    "    plot = '''['Mika, a boy with kind eyes, explores the lush jungle, playfully interacting with a troop of monkeys swinging through the trees.  A majestic banyan tree looms in the background.', \"Mika discovers a weak, thin lion cub, Leo, whimpering under the banyan tree.  Leo's dull eyes and ribs showing through his fur highlight his hunger.\", 'Mika gently shares his mangoes and later sweet potatoes with the hungry cub. Leo cautiously eats, his tail thumping weakly as he gains strength.', \"Days later, a healthy Leo playfully wrestles with Mika amidst the jungle undergrowth.  Mika's father watches from afar, initially concerned but then understanding.\", 'Mika watches from a distance as Leo, now strong and vibrant, plays with his mother, a magnificent lioness, under the banyan tree.  The scene is peaceful and joyful.']'''\n",
    "    character_description = \"\"\"**Main Characters:**\n",
    "\n",
    "    * **Mika:** A boy who lives in a lush green jungle. He is adventurous, kind, and resourceful, possessing intimate knowledge of the jungle's secrets.  He is depicted as having a compassionate heart, evident in his care for Leo.  No specific physical description is given.\n",
    "\n",
    "    * **Leo:** A tiny lion cub, initially weak and undernourished, with thin, dusty fur and dull eyes. As he recovers, his fur becomes thicker and shinier, and his eyes sparkle with playful energy.\n",
    "\n",
    "    * **Leo's Mother:** A large lioness with a magnificent mane.  She is depicted as cautious but ultimately grateful and understanding of Mika's kindness.\n",
    "\n",
    "\n",
    "    **Supporting Characters/Elements:**\n",
    "\n",
    "    * **Monkeys:**  Inhabit the jungle trees and are Mika's friends. No specific details are given about their appearance.\n",
    "\n",
    "    * **Rhinoceroses:** Described as \"grumpy\" and inhabiting the jungle. No specific details are given about their appearance.\n",
    "\n",
    "    * **Banyan Tree:** A large tree where Mika finds the lion cub.\n",
    "\n",
    "    **Objects:**\n",
    "\n",
    "    * **Mangoes:** Juicy mangoes that Mika shares with Leo.\n",
    "\n",
    "    * **Berries:**  Food collected by Mika and shared with Leo.\n",
    "    ...\n",
    "    * **Banyan Tree Scene:** The scene where Mika discovers the weak lion cub under the banyan tree.\n",
    "\n",
    "    * **Final Scene:** Mika observes Leo and his mother together, thriving in the jungle.\"\"\"\n",
    "    generate_description_prompt = f\"\"\"Based on this plot: '{plot}' and featuring this description: {character_description}, generate 5 specific, family-friendly image prompts, one for each step. Each prompt should be detailed enough for image generation, maintaining consistency, and suitable for DALL-E. \n",
    "\n",
    "                                    Always include the following in EVERY prompt to maintain consistency:\n",
    "                                    1. A brief reminder of the main character or object's key features\n",
    "                                    2. The specific action or scene described in the plot step\n",
    "                                    3. Any relevant background or environmental details\n",
    "\n",
    "                                    Format each prompt as a numbered list item, like this:\n",
    "                                    1. [Your prompt here]\n",
    "                                    2. [Your prompt here]\n",
    "                                    ... and so on.\n",
    "                                        \"\"\"\n",
    "    \n",
    "\n",
    "    hum_msg = HumanMessage(content=generate_description_prompt.format(character_description=character_description, plot=plot))\n",
    "    response = llm.invoke([hum_msg])\n",
    "    prompts = []\n",
    "    for line in response.content.split(\"\\n\"):\n",
    "        if line.strip().startswith((\"1.\", \"2.\", \"3.\", \"4.\", \"5.\")):\n",
    "            prompt = line.split(\".\", 1)[1].strip()\n",
    "            prompts.append(\n",
    "                f\"Create a detailed, photorealistic image of the following scene: {prompt}\"\n",
    "            )\n",
    "\n",
    "    if len(prompts) != 5:\n",
    "        raise ValueError(\n",
    "            f\"Expected 5 prompts, but got {len(prompts)}. Please try again.\"\n",
    "        )\n",
    "\n",
    "    state[\"image_prompts\"] = prompts\n",
    "    return state\n",
    "  \n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_plot', generate_plot)\n",
    "workflow.add_edge(START, 'generate_plot')\n",
    "workflow.add_edge('generate_plot', END)\n",
    "app = workflow.compile()\n",
    "\n",
    "story = \"\"\"Once upon a time, deep in a lush green jungle, lived a boy named Mika. Mika wasn't like the other children in his village. While they played near their homes, Mika loved exploring the jungle, its secrets whispering to him in the rustling leaves and the calls of unseen birds. He knew the paths like the back of his hand, and the jungle felt like a second home.\n",
    "\n",
    "One sweltering afternoon, while searching for juicy mangoes, Mika stumbled upon a tiny lion cub, huddled under a giant banyan tree. The cub was thin, its ribs showing through its tawny fur. Its eyes, usually bright and playful, were dull with hunger. A whimper escaped its tiny mouth. Mika’s heart ached. He knew what hunger felt like; sometimes his family didn't have enough to eat.\n",
    "\n",
    "Carefully, Mika approached the cub. He offered it a half-eaten mango, holding it out gently in his palm. The cub, hesitant at first, sniffed the fruit cautiously before lapping at the sweet juice. Mika smiled. He shared the rest of his mangoes with the cub, and then, remembering the sweet potatoes his mother had packed for him, he offered those too. The cub ate greedily, its tail thumping weakly against the ground.\n",
    "\n",
    "Day after day, Mika visited the cub, bringing it food he found or shared from his own meals. He named the cub Leo. Slowly, Leo grew stronger, his fur regaining its shine, his eyes sparkling with life. They played together, Mika chasing Leo through the undergrowth, Leo playfully batting at Mika's legs. A unique friendship blossomed between a boy and a lion cub, a bond forged in shared hunger and kindness.\n",
    "\n",
    "One day, Mika’s father saw him playing with Leo. He was worried at first, but Mika explained their friendship. To his surprise, his father understood. He knew the jungle was full of wonders, and that sometimes, the greatest friendships came from the most unexpected places. Mika and Leo continued their adventures, their bond a testament to the power of kindness and the magic of the jungle. And so, the boy who lived in the jungle and his lion cub friend lived happily, their story whispered on the jungle breeze.\"\"\"\n",
    "\n",
    "resp = app.invoke({'story': story})\n",
    "print(resp['image_prompts'])\n",
    "print(type(resp['image_prompts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from datetime import datetime\n",
    "class GraphState(TypedDict): \n",
    "    sceneList: list[str]\n",
    "\n",
    "\n",
    "def voice_generates(text: str, file_name: str, folder: str):\n",
    "    try:\n",
    "        tts = gTTS(text)\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        save_path = os.path.join(folder, file_name)\n",
    "        tts.save(save_path)\n",
    "        return save_path\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def finalvoicefun(sceneList):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    dynamic_folder_voice = f\"voice_{timestamp}\"\n",
    "    output_folder_voice = os.path.join(\"Generated_voice\", dynamic_folder_voice)\n",
    "    voice_paths = []\n",
    "    for i, scene in enumerate(sceneList):\n",
    "        try:\n",
    "            voice_path = voice_generates(\n",
    "                scene, f\"voice_scene_{i+1}.mp3\", output_folder_voice\n",
    "            )\n",
    "\n",
    "            if voice_path:\n",
    "                voice_paths.append(voice_path)\n",
    "                print(f\"Voiceover saved locally: {voice_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to save voiceover for scene {i+1}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating voice for scene {i+1}: {e}\")\n",
    "    return output_folder_voice    \n",
    "\n",
    "def generate_scence_voice(state:GraphState)->GraphState:\n",
    "    sceneList = state['sceneList']\n",
    "    resp = finalvoicefun(sceneList) \n",
    "    print(f\"Generating voice{resp}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_scence_voice',generate_scence_voice)\n",
    "workflow.add_edge(START,'generate_scence_voice')\n",
    "workflow.add_edge('generate_scence_voice',END)\n",
    "app = workflow.compile()\n",
    "\n",
    "sceneList = [\n",
    "    \"Mika, a boy with kind eyes, explores the lush jungle, playfully interacting with a troop of monkeys swinging through the trees.  A majestic banyan tree looms in the background.\",\n",
    "  ]  \n",
    "resp = app.invoke({'sceneList':sceneList})\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "\n",
    "class GraphState(TypedDict): \n",
    "    image_prompts: list[str]\n",
    "    image_saved_path:str\n",
    "    \n",
    "\n",
    "\n",
    "def saveImage(image_content, save_path):\n",
    "    output_folder = os.path.dirname(save_path)\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(image_content)\n",
    "\n",
    "\n",
    "def images_generates(prompt: str):\n",
    "    try:\n",
    "        # response = client.images.generate(\n",
    "        #     model=imagemodel,\n",
    "        #     prompt=prompt,\n",
    "        #     quality=\"standard\",\n",
    "        #     n=1,\n",
    "        # )\n",
    "        # image_url = response.data[0].url\n",
    "        image_url = \"https://www.w3schools.com/w3images/lights.jpg\"\n",
    "        return image_url\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error generating image: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def finalscenesfun(image_prompts):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    dynamic_folder = f\"images_{timestamp}\"\n",
    "    output_folder = os.path.join(\"Generated_images\", dynamic_folder)\n",
    "\n",
    "    for i, scene in enumerate(image_prompts):\n",
    "        try:\n",
    "             \n",
    "            imageUrl = images_generates(scene)\n",
    "            if not imageUrl:\n",
    "                raise ValueError(\"Generated image URL is empty.\")\n",
    "\n",
    "            imageContent = requests.get(imageUrl).content\n",
    "            if not imageContent:\n",
    "                raise ValueError(\"Failed to retrieve image content.\")\n",
    "\n",
    "            save_path = os.path.join(output_folder, f\"image_scene_{i+1}.png\")\n",
    "            saveImage(imageContent, save_path)\n",
    "            print(f\"Images saved to {save_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing scene {i+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return output_folder\n",
    "\n",
    "def generate_scence_image(state:GraphState)->GraphState:\n",
    "    image_prompts = state['image_prompts']\n",
    "    resp = finalscenesfun(image_prompts) \n",
    "    state[\"image_saved_path\"]=resp\n",
    "    print(f\"Generating images path: {resp}\")\n",
    "    return state\n",
    "\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('generate_scence_image',generate_scence_image)\n",
    "workflow.add_edge(START,'generate_scence_image')\n",
    "workflow.add_edge('generate_scence_image',END)\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "image_prompts = [\n",
    "    \"Create a detailed, photorealistic image of the following scene: A young boy, Mika, with kind eyes and dark hair, playfully interacts with a troop of brown and grey monkeys swinging through the lush green canopy of a vibrant jungle.  A majestic, sprawling banyan tree with thick, gnarled roots dominates the background.  The scene is filled with sunlight dappling through the leaves.  Style: vibrant, whimsical illustration.\",\n",
    "    \"Create a detailed, photorealistic image of the following scene: Under the shade of a massive banyan tree, a thin, weak lion cub, Leo, with dull eyes and ribs showing through his dusty fur, whimpers.  A young boy, Mika, kneels beside him, offering a juicy mango. The jungle floor is dappled with sunlight, and the air is humid. Style: realistic, slightly painterly.\",\n",
    "    \"Create a detailed, photorealistic image of the following scene: Days later, a healthier lion cub, Leo, with thicker, shinier fur and bright eyes, playfully wrestles with Mika amidst the lush undergrowth of a tropical jungle.  Mika's father, a man with weathered skin and kind eyes, watches from a distance, a slight smile on his face. Style:  photorealistic, warm lighting.\",\n",
    "    \"Create a detailed, photorealistic image of the following scene: A strong and vibrant lion cub, Leo, playfully tumbles with his magnificent lioness mother under the sprawling branches of a large banyan tree.  Mika, the kind boy who helped him, watches from a distance with a happy expression. The jungle is bathed in the golden light of late afternoon. Style:  impressionistic, focusing on light and color.\",\n",
    "    \"Create a detailed, photorealistic image of the following scene: Mika, a boy with a gentle smile, observes from afar as Leo, now a healthy and playful lion cub with thick, glossy fur, frolics with his majestic lioness mother under a large banyan tree. The scene is peaceful and joyful, filled with the sounds of the jungle.  The banyan tree's roots spread wide, creating a natural haven. Style:  peaceful, serene illustration, emphasizing the bond between Leo and his mother.\",\n",
    "]\n",
    "resp = app.invoke({'image_prompts':image_prompts}) \n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of Generated_voice/voice_20250320130830\\voice_scene_1.mp3: 13.75 seconds\n",
      "Duration of Generated_voice/voice_20250320130830\\voice_scene_2.mp3: 12.26 seconds\n",
      "Duration of Generated_voice/voice_20250320130830\\voice_scene_3.mp3: 11.35 seconds\n",
      "Duration of Generated_voice/voice_20250320130830\\voice_scene_4.mp3: 12.96 seconds\n",
      "Duration of Generated_voice/voice_20250320130830\\voice_scene_5.mp3: 13.92 seconds\n",
      "Duration of Generated_voice/voice_20250320130830\\voice_scene_6.mp3: 13.92 seconds\n",
      "Total frames written: 442\n",
      "Total frames written: 427\n",
      "Total frames written: 400\n",
      "Total frames written: 448\n",
      "Total frames written: 477\n",
      "Total frames written: 477\n",
      "Video saved as ./final_outputs/output1254.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from moviepy import *\n",
    "def zoom_in(image, num_frames=30, zoom_factor=0.5): \n",
    "    \"\"\"Generates frames for a zoom-in effect.\"\"\"\n",
    "    frames = []\n",
    "    h, w = image.shape[:2]\n",
    "    for i in range(num_frames):\n",
    "        scale = 1.0 + (i / num_frames) * zoom_factor\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "        frame = cv2.warpAffine(image, M, (w, h))\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def zoom_out(image, num_frames=30, zoom_factor=0.5): \n",
    "    \"\"\"Generates frames for a zoom-out effect without blinking.\"\"\"\n",
    "    frames = []\n",
    "    h, w = image.shape[:2]\n",
    "    for i in range(num_frames):\n",
    "        scale = 1.0 + ((num_frames - i - 1) / num_frames) * zoom_factor   \n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "        frame = cv2.warpAffine(image, M, (w, h))\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def fade_in(image, num_frames=30): \n",
    "    \"\"\"Creates a fade-in effect from black to the image.\"\"\"\n",
    "    frames = []\n",
    "    black = np.zeros_like(image)\n",
    "    for i in range(num_frames):\n",
    "        alpha = i / num_frames\n",
    "        frame = cv2.addWeighted(image, alpha, black, 1 - alpha, 0)\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def fade_out(image, num_frames=30): \n",
    "    \"\"\"Creates a fade-out effect from image to black.\"\"\"\n",
    "    frames = []\n",
    "    black = np.zeros_like(image)\n",
    "    for i in range(num_frames):\n",
    "        alpha = 1 - i / num_frames\n",
    "        frame = cv2.addWeighted(image, alpha, black, 1 - alpha, 0)\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "def load_voices(voices_root_folder):\n",
    "    try:\n",
    "        # Ensure paths are strings\n",
    "        if not isinstance(voices_root_folder, str):\n",
    "            raise ValueError(\"Voice folder path should be a string.\") \n",
    "        \n",
    "        voices = sorted([\n",
    "            os.path.join(voices_root_folder, voice)\n",
    "            for voice in os.listdir(voices_root_folder)\n",
    "            if voice.lower().endswith('.mp3')\n",
    "        ])\n",
    "        return voices\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error in load_voices function: {e}\")\n",
    "def images_to_video_with_effects(image_paths, output_video=\"output.mp4\", fps=30, durations=None): \n",
    "    \"\"\"Converts a list of images into a video with zoom and fade effects.\"\"\"\n",
    "    \n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No images provided.\") \n",
    "    \n",
    "    first_img = cv2.imread(image_paths[0])\n",
    "    if first_img is None:\n",
    "        raise ValueError(f\"Cannot load image: {image_paths[0]}\")\n",
    "        \n",
    "    h, w, _ = first_img.shape \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_video, fourcc, fps, (w, h))\n",
    "\n",
    "    # Default durations if not provided\n",
    "    if durations is None:\n",
    "        durations = [2] * len(image_paths)  # Default 2 seconds per image\n",
    "\n",
    "    for idx, (path, duration) in enumerate(zip(image_paths, durations)):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Cannot load image {path}. Skipping.\")\n",
    "            continue \n",
    "        img = cv2.resize(img, (w, h))\n",
    "\n",
    "        frame_duration = int(fps * duration)  # Convert duration to frames\n",
    "        \n",
    "        if idx == 0: \n",
    "            zoom_in_frames = zoom_in(img, num_frames=frame_duration, zoom_factor=0.5)  \n",
    "            final_zoom_frame = zoom_in_frames[-1]  \n",
    "            fade_out_frames = fade_out(final_zoom_frame, num_frames=int(fps * 1))  \n",
    "            effect_frames = zoom_in_frames + fade_out_frames  \n",
    "        else:  \n",
    "            fade_in_frames = fade_in(img, num_frames=int(fps * 1))  \n",
    "            fade_out_frames = fade_out(img, num_frames=int(fps * 1))  \n",
    "            steady_frames = [img] * frame_duration  \n",
    "            effect_frames = fade_in_frames + steady_frames + fade_out_frames\n",
    "        print(f\"Total frames written: {len(effect_frames)}\")\n",
    "\n",
    "        for frame in effect_frames:\n",
    "            video_writer.write(frame)\n",
    "    \n",
    "    video_writer.release()\n",
    "    print(f\"Video saved as {output_video}\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "image_folder = \"Generated_images/images_20250320130205\"\n",
    "voice_generates_folder = \"Generated_voice/voice_20250320130830\"\n",
    "output_path = \"./final_outputs/output1254.mp4\"\n",
    "fps = 30 \n",
    "voices = load_voices(voice_generates_folder)\n",
    "image_paths = sorted([\n",
    "    os.path.join(image_folder, img) \n",
    "    for img in os.listdir(image_folder) \n",
    "    if img.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "])\n",
    "\n",
    "display_durations = []\n",
    "for file_path in voices:\n",
    "    try:\n",
    "        audio = AudioFileClip(file_path)\n",
    "        duration_sec = audio.duration\n",
    "        display_durations.append(duration_sec)\n",
    "        print(f\"Duration of {file_path}: {duration_sec} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Generate video\n",
    "images_to_video_with_effects(image_paths, output_video=output_path, fps=fps, durations=display_durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
