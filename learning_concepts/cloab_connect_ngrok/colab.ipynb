{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers diffusers accelerate fastapi uvicorn nest-asynci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, UNet2DConditionModel, EulerDiscreteScheduler\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "base = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "repo = \"ByteDance/SDXL-Lightning\"\n",
    "ckpt = \"sdxl_lightning_4step_unet.safetensors\" # Use the correct ckpt for your step setting!\n",
    "\n",
    "# Load model.\n",
    "unet = UNet2DConditionModel.from_config(base, subfolder=\"unet\").to(\"cuda\", torch.float16)\n",
    "unet.load_state_dict(load_file(hf_hub_download(repo, ckpt), device=\"cuda\"))\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(base, unet=unet, torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
    "\n",
    "# Ensure sampler uses \"trailing\" timesteps.\n",
    "pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import FileResponse\n",
    "from pyngrok import ngrok\n",
    "import torch\n",
    "from diffusers import StableDiffusionXLPipeline, UNet2DConditionModel, EulerDiscreteScheduler\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "import uuid\n",
    "import os\n",
    "from google.colab import userdata\n",
    "from fastapi.responses import StreamingResponse\n",
    "from io import BytesIO\n",
    "\n",
    "NGROK_AUTH_TOKEN=userdata.get('NGROK_AUTH_TOKEN')\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN) # Replace with your actual authtoken\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
    "@app.post(\"/generatenew\")\n",
    "async def generate(request: Request):\n",
    "    data = await request.json()\n",
    "    prompt = data.get(\"prompt\", \"A cat sitting on a rocket\")\n",
    "    image = pipe(prompt).images[0]\n",
    "    \n",
    "    # Convert the image to bytes in PNG format\n",
    "    image_bytes = BytesIO()\n",
    "    image.save(image_bytes, format='PNG')\n",
    "    image_bytes.seek(0)\n",
    "    \n",
    "    return StreamingResponse(image_bytes, media_type=\"image/png\")\n",
    " \n",
    "@app.post(\"/generate\")\n",
    "async def generate(request: Request):\n",
    "    data = await request.json()\n",
    "    prompt = data.get(\"prompt\", \"A cat sitting on a rocket\")\n",
    "    image = pipe(prompt).images[0]\n",
    "    print(f'image:{image}')\n",
    "    image_path = f\"/content/{arman.hex}.png\"\n",
    "    image.save(image_path)\n",
    "    return {\"image_url\": ngrok_tunnel.public_url + \"/image/\" + os.path.basename(image_path),\"image\":image}\n",
    "\n",
    "@app.get(\"/image/{img_name}\")\n",
    "def serve_image(img_name: str):\n",
    "    path = f\"/content/{img_name}\"\n",
    "    return FileResponse(path, media_type=\"image/png\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_img_prompt = \"\"\"Create a detailed, photorealistic image of the following scene:\\n        Leo spots a lion.\\n        \\n        **Main Characters**:\\n        Leo - A young boy with bright eyes and short brown hair, wearing a simple, slightly torn shirt and shorts., Curious, adventurous, a little bit scared but brave.\\n \\n\\n   \"\"\"  \n",
    "resp=pipe(user_img_prompt,negative_prompt=\"anime, illustration\", num_inference_steps=8, guidance_scale=0).images[0] \n",
    "display(resp)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
