{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Despite the lengthy processing time, the voice quality is satisfactory.\n",
    "import time\n",
    "def call_llm_gen_voice(voice):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        tts = gTTS(voice)\n",
    "        tts.save('./output/res0.mp3')\n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to generate voice: {end_time - start_time} seconds')  \n",
    "        return tts\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error while generating the voice\", e)\n",
    "call_llm=call_llm_gen_voice('this is arman')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The process is excessively fast, and the resulting voice quality is extremely poor.\n",
    "import pyttsx3\n",
    "\n",
    "def call_llm_gen_voice(voice):\n",
    "    try:\n",
    "        start_time= time.time()\n",
    "        engine = pyttsx3.init()\n",
    "        engine.save_to_file(voice, './output/res1.mp3')   \n",
    "        engine.runAndWait()  \n",
    "        end_time= time.time()\n",
    "        print(f'Time taken to generate voice: {end_time - start_time} seconds')\n",
    "        return \"Voice saved successfully!\"\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error while generating the voice\", e)\n",
    "\n",
    "call_llm = llm=call_llm_gen_voice('this is arman')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-2' coro=<main() running at C:\\Users\\arman\\AppData\\Local\\Temp\\ipykernel_15980\\1753653568.py:25>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The processing time is reasonable, and the voice quality is excellent.\n",
    "import asyncio\n",
    "import edge_tts\n",
    "\n",
    "async def call_llm_gen_voice(voice):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        #  tts = edge_tts.Communicate(\n",
    "        #     text=\"Hello! How are you today?\",\n",
    "        #     voice=\"en-US-JennyNeural\",\n",
    "        #     rate=\"+10%\",\n",
    "        #     volume=\"+0%\",\n",
    "        #     pitch=\"+5Hz\"\n",
    "        # ) \n",
    "         \n",
    "        tts = edge_tts.Communicate(voice, voice=\"en-US-JennyNeural\")  \n",
    "        await tts.save(\"./output/res2.mp3\")\n",
    "        end_time = time.time()\n",
    "        print(f'Time taken to generate voice: {end_time - start_time} seconds')\n",
    "        print(\"Voice saved successfully!\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error while generating the voice\", e)\n",
    " \n",
    "async def main():\n",
    "    await call_llm_gen_voice(\"This is Arman\") \n",
    " \n",
    "asyncio.create_task(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ar-AE-FatimaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar-AE-HamdanNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ar-BH-AliNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ar-BH-LailaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-BH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ar-DZ-AminaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ar-DZ-IsmaelNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ar-EG-SalmaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ar-EG-ShakirNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-EG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ar-IQ-BasselNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ar-IQ-RanaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-IQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ar-JO-SanaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-JO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ar-JO-TaimNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-JO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ar-KW-FahedNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-KW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ar-KW-NouraNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-KW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ar-LB-LaylaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ar-LB-RamiNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ar-LY-ImanNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ar-LY-OmarNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ar-MA-JamalNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ar-MA-MounaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ar-OM-AbdullahNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-OM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ar-OM-AyshaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-OM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ar-QA-AmalNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ar-QA-MoazNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-QA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ar-SA-HamedNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ar-SA-ZariyahNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ar-SY-AmanyNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-SY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ar-SY-LaithNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-SY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ar-TN-HediNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ar-TN-ReemNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ar-YE-MaryamNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ar-YE-SalehNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>ar-YE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  Gender Language\n",
       "0     ar-AE-FatimaNeural  Female    ar-AE\n",
       "1     ar-AE-HamdanNeural    Male    ar-AE\n",
       "2        ar-BH-AliNeural    Male    ar-BH\n",
       "3      ar-BH-LailaNeural  Female    ar-BH\n",
       "4      ar-DZ-AminaNeural  Female    ar-DZ\n",
       "5     ar-DZ-IsmaelNeural    Male    ar-DZ\n",
       "6      ar-EG-SalmaNeural  Female    ar-EG\n",
       "7     ar-EG-ShakirNeural    Male    ar-EG\n",
       "8     ar-IQ-BasselNeural    Male    ar-IQ\n",
       "9       ar-IQ-RanaNeural  Female    ar-IQ\n",
       "10      ar-JO-SanaNeural  Female    ar-JO\n",
       "11      ar-JO-TaimNeural    Male    ar-JO\n",
       "12     ar-KW-FahedNeural    Male    ar-KW\n",
       "13     ar-KW-NouraNeural  Female    ar-KW\n",
       "14     ar-LB-LaylaNeural  Female    ar-LB\n",
       "15      ar-LB-RamiNeural    Male    ar-LB\n",
       "16      ar-LY-ImanNeural  Female    ar-LY\n",
       "17      ar-LY-OmarNeural    Male    ar-LY\n",
       "18     ar-MA-JamalNeural    Male    ar-MA\n",
       "19     ar-MA-MounaNeural  Female    ar-MA\n",
       "20  ar-OM-AbdullahNeural    Male    ar-OM\n",
       "21     ar-OM-AyshaNeural  Female    ar-OM\n",
       "22      ar-QA-AmalNeural  Female    ar-QA\n",
       "23      ar-QA-MoazNeural    Male    ar-QA\n",
       "24     ar-SA-HamedNeural    Male    ar-SA\n",
       "25   ar-SA-ZariyahNeural  Female    ar-SA\n",
       "26     ar-SY-AmanyNeural  Female    ar-SY\n",
       "27     ar-SY-LaithNeural    Male    ar-SY\n",
       "28      ar-TN-HediNeural    Male    ar-TN\n",
       "29      ar-TN-ReemNeural  Female    ar-TN\n",
       "30    ar-YE-MaryamNeural  Female    ar-YE\n",
       "31     ar-YE-SalehNeural    Male    ar-YE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from edge_tts import list_voices\n",
    "\n",
    "# Fix for running asyncio inside Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_arabic_voices():\n",
    "    \"\"\"Fetch and return only Arabic voices as a pandas DataFrame.\"\"\"\n",
    "    voices = await list_voices()\n",
    "    voices = sorted(voices, key=lambda voice: voice[\"ShortName\"])\n",
    "    \n",
    "    # Keep only voices where Language starts with 'ar'\n",
    "    arabic_voices = [v for v in voices if v[\"Locale\"].startswith(\"ar\")]\n",
    "    \n",
    "    df = pd.DataFrame(arabic_voices, columns=[\"ShortName\", \"Gender\", \"Locale\"])\n",
    "    df.rename(columns={\"ShortName\": \"Name\", \"Locale\": \"Language\"}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "async def main():\n",
    "    df = await get_arabic_voices()\n",
    "    display(df)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af-ZA-AdriNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>af-ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>af-ZA-WillemNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>af-ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>am-ET-AmehaNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>am-ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>am-ET-MekdesNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>am-ET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ar-AE-FatimaNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>ar-AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>zh-TW-HsiaoChenNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>zh-TW-HsiaoYuNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>zh-TW-YunJheNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>zh-TW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>zu-ZA-ThandoNeural</td>\n",
       "      <td>Female</td>\n",
       "      <td>zu-ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>zu-ZA-ThembaNeural</td>\n",
       "      <td>Male</td>\n",
       "      <td>zu-ZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name  Gender Language\n",
       "0         af-ZA-AdriNeural  Female    af-ZA\n",
       "1       af-ZA-WillemNeural    Male    af-ZA\n",
       "2        am-ET-AmehaNeural    Male    am-ET\n",
       "3       am-ET-MekdesNeural  Female    am-ET\n",
       "4       ar-AE-FatimaNeural  Female    ar-AE\n",
       "..                     ...     ...      ...\n",
       "545  zh-TW-HsiaoChenNeural  Female    zh-TW\n",
       "546    zh-TW-HsiaoYuNeural  Female    zh-TW\n",
       "547     zh-TW-YunJheNeural    Male    zh-TW\n",
       "548     zu-ZA-ThandoNeural  Female    zu-ZA\n",
       "549     zu-ZA-ThembaNeural    Male    zu-ZA\n",
       "\n",
       "[550 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from edge_tts import list_voices\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Fix for running asyncio inside Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_voices():\n",
    "    \"\"\"Fetch and return available voices as a pandas DataFrame.\"\"\"\n",
    "    voices = await list_voices()  \n",
    "    voices = sorted(voices, key=lambda voice: voice[\"ShortName\"]) \n",
    " \n",
    "    df = pd.DataFrame(voices, columns=[\"ShortName\", \"Gender\", \"Locale\"])\n",
    "    df.rename(columns={\"ShortName\": \"Name\", \"Locale\": \"Language\"}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "async def main():\n",
    "    df = await get_voices() \n",
    "    display(df)\n",
    " \n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error generating voice ur-IN-GulNeuralaf-ZA-AdriNeural: No audio was received. Please verify that your parameters are correct.\n",
      "âŒ Error generating voice ur-IN-SalmanNeural: Connection timeout to host wss://api.msedgeservices.com/tts/cognitiveservices/websocket/v1?Ocp-Apim-Subscription-Key=6A5AA1D4EAFF4E9FB37E23D68491D6F4&ConnectionId=7890e95a1a0748f2b70005a2031fbd69&Sec-MS-GEC=D75B98BC63A10FE3843E44A82514300C078175F08726AFF11B9E9206B7BCF661&Sec-MS-GEC-Version=1-140.0.3485.14\n",
      "âœ… Voice ur-PK-AsadNeural saved successfully! Time taken: 33.28 seconds\n",
      "âœ… Voice ur-PK-UzmaNeural saved successfully! Time taken: 54.69 seconds\n"
     ]
    }
   ],
   "source": [
    "# list of voices\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Create output directory if not exists\n",
    "output_dir = \"outputssurdu\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    " \n",
    "voices = [\n",
    "    \"ur-IN-GulNeuralaf-ZA-AdriNeural\",\n",
    "    \"ur-IN-SalmanNeural\",\n",
    "    \"ur-PK-AsadNeural\",\n",
    "    \"ur-PK-UzmaNeural\",\n",
    "   \n",
    "]  # You can add more voices\n",
    "\n",
    "async def generate_voice(voice_name, text=\"\"\"Ø§ÛŒÚ© Ø¯ÙØ¹Û Ú©Ø§ Ø°Ú©Ø± ÛÛ’ Ú©Û Ø§ÛŒÚ© Ù¾ÛŒØ§Ø³Ø§ Ú©ÙˆØ§ Ù¾ÛŒØ§Ø³ Ú©ÛŒ Ø´Ø¯Øª Ø³Û’ Ù†ÚˆÚ¾Ø§Ù„ Ù¾Ø§Ù†ÛŒ Ú©ÛŒ ØªÙ„Ø§Ø´ Ù…ÛŒÚº ÛŒÛØ§Úº ÙˆÛØ§Úº Ø³Ø±Ú¯Ø±Ø¯Ø§Úº ØªÚ¾Ø§ØŒ Ú©Û Ø±Ø­Ù…Øª Ø®Ø¯Ø§ÙˆÙ†Ø¯ÛŒ Ø¬ÙˆØ´ Ù…ÛŒÚº Ø¢Ø¦ÛŒ Ø§ÙˆØ± Ø§Ø³ Ø¨ÛŒÚ†Ø§Ø±Û’ Ú©ÙˆÛ’ Ù†Û’ Ø§ÛŒÚ© Ø¨Ø§Øº Ù…ÛŒÚº Ù¾Ú‘Û’ Ù…Ù¹Ú©Û’ Ù…ÛŒÚº Ù¾Ø§Ù†ÛŒ Ú©ÛŒ Ú†Ù…Ú© Ø¯ÛŒÚ©Ú¾ÛŒÛ” Ú©ÙˆØ§ Ø§ØªØ±Ø§ Ù„ÛŒÚ©Ù† ÛŒÛ Ø¬Ø§Ù† Ú©Ø± Ù…Ø§ÛŒÙˆØ³ ÛÙˆØ§ Ú©Û Ù¾Ø§Ù†ÛŒ Ù…Ù¹Ú©Û’ Ú©Û’ Ù¾ÛŒÙ†Ø¯Û’ Ù…ÛŒÚº ØªÚ¾ÙˆÚ‘Ø§ Ø³Ø§ ÛÛ’Û” Ø§Ø³ Ù¾ÛŒØ§Ø³Û’ Ú©Ùˆ Ú©Ú†Ú¾ Ù†Ø§ Ø³ÙˆØ¬Ú¾Ø§ Ú©Û Ø¯ÙØ¹ØªØ§ Ø±Ø­Ù…Øª Ø®Ø¯Ø§ÙˆÙ†Ø¯ÛŒ Ù¾Ú¾Ø± Ø¬ÙˆØ´ Ù…ÛŒÚº Ø¢Ø¦ÛŒ Ø§ÙˆØ± Ø¢Ù¾ Ú©ÛŒ Ø·Ø±Ø­ Ø§Ø³Û’ Ø¨Ú¾ÛŒ Ø¹Ù‚Ù„Ù…Ù†Ø¯ Ù¾ÛŒØ§Ø³Û’ Ú©ÙˆÛ’ ÙˆØ§Ù„ÛŒ Ú©ÛØ§Ù†ÛŒ ÛŒØ§Ø¯ Ø¢Ø¦ÛŒÛ” Ú©ÙˆÛ’ Ù†Û’ Ø¢Ùˆ Ø¯ÛŒÚ©Ú¾Ø§ Ù†Ø§ ØªØ§Ø¤ Ù¾ØªÚ¾Ø± Ø¬Ù…Ø¹ Ú©Ø¦Û’ Ø§ÙˆØ± Ø®ÛŒØ§Ù„ Ú©Ø±ØªÛ’ ÛÙˆØ¦Û’ Ú©Û ÛŒÙˆÚº Ù¾Ø§Ù†ÛŒ Ù…Ù¹Ú©Û’ Ú©Ø§ Ù¾Ø§Ù†ÛŒ Ø§ÙˆÙ¾Ø± Ø¢Ø¬Ø§Ø¦Û’ Ú¯Ø§ Ø¬ÛŒØ³Ø§ Ú©Û Ú©ÛØ§Ù†ÛŒ Ù…ÛŒÚº Ú©ÛØ§ Ø¬Ø§ØªØ§ ÛÛ’Û” Ù„ÛŒÚ©Ù† ÛŒÛ Ú©ÛŒØ§ØŸ Ú©ÙˆÛ’ Ù†Û’ Ø¯ÛŒÚ©Ú¾Ø§ Ú©Û’ Ù¾ÛÙ„Û’ Ø¬Ùˆ ØªÚ¾ÙˆÚ‘Ø§ Ø³Ø§ Ù¾Ø§Ù†ÛŒ ØªÚ¾Ø§ ÙˆÛ Ø¨Ú¾ÛŒ Ø¨Ú¾ÛŒ Ù¾ØªÚ¾Ø±ÙˆÚº Ù†Û’ Ú†ÙˆØ³ Ù„ÛŒØ§ÛÛ’ Ø§ÙˆØ± Ù…Ù¹Ú©Û’ Ù…ÛŒÚº Ú©Ú†Ú¾ Ø¨Ú¾ÛŒ Ù†ÛÛŒ Ø¨Ú†Ø§Û” Ù¾ÛŒØ§Ø³Ø§ Ú©ÙˆØ§ ÙˆÛŒØ³ÛŒ Ù†ÚˆÚ¾Ø§Ù„ ØªÚ¾Ø§ Ù¾ØªÚ¾Ø± Ø§Ù¹Ú¾Ø§ Ú©Ø± ÚˆØ§Ù„Ù†Û’ Ø³Û’ Ø§Ø³Ú©ÛŒ Ø±ÛÛŒ Ø³ÛÛŒ Ø³Ú©Øª Ø¨Ú¾ÛŒ Ø®ØªÙ… ÛÙˆÚ†Ú©ÛŒ ØªÚ¾ÛŒØŒ Ø§Ø³ Ø³Û’ ÛŒÛ ØºÙ… Ø¨Ø±Ø¯Ø§Ø´Øª Ù†Ø§ ÛÙˆØ³Ú©Ø§ Ø§ÙˆØ± ÙˆÛÛŒÚº Ø¬Ø§Ø¨Ø­Ù‚ ÛÙˆÚ¯ÛŒØ§Û”\n",
    "\n",
    "Ù†ØªÛŒØ¬Û: Ú©ØªØ§Ø¨ÙˆÚº Ù…ÛŒÚº Ù„Ú©Ú¾ÛŒ ÛØ± Ø¨Ø§Øª Ø¯Ø±Ø³Øª Ù†ÛÛŒÚº ÛÙˆØªÛŒÛ”\"\"\"):\n",
    "    \"\"\"Generate speech using the given voice and save it as a file.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        filename = f\"{output_dir}/{voice_name}.mp3\"\n",
    "        \n",
    "        # Generate voice\n",
    "        tts = edge_tts.Communicate(text, voice=voice_name)\n",
    "        await tts.save(filename)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"âœ… Voice {voice_name} saved successfully! Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating voice {voice_name}: {e}\")\n",
    "\n",
    "async def process_voices():\n",
    "    \"\"\"Process voices sequentially to avoid overwhelming the system.\"\"\"\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    # Add voices to queue\n",
    "    for voice in voices:\n",
    "        await queue.put(voice)\n",
    "\n",
    "    while not queue.empty():\n",
    "        voice_name = await queue.get()\n",
    "        await generate_voice(voice_name)\n",
    "        queue.task_done()\n",
    "\n",
    "async def main():\n",
    "    await process_voices()\n",
    "\n",
    "# âœ… Run the async function safely\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting edge_tts\n",
      "  Downloading edge_tts-7.2.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from edge_tts) (3.12.13)\n",
      "Requirement already satisfied: certifi>=2023.11.17 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from edge_tts) (2025.6.15)\n",
      "Collecting tabulate<1.0.0,>=0.4.4 (from edge_tts)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from edge_tts) (4.14.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp<4.0.0,>=3.8.0->edge_tts) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\arman\\appdata\\roaming\\python\\python39\\site-packages (from yarl<2.0,>=1.17.0->aiohttp<4.0.0,>=3.8.0->edge_tts) (3.10)\n",
      "Downloading edge_tts-7.2.3-py3-none-any.whl (30 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate, edge_tts\n",
      "\n",
      "   ---------------------------------------- 0/2 [tabulate]\n",
      "   -------------------- ------------------- 1/2 [edge_tts]\n",
      "   -------------------- ------------------- 1/2 [edge_tts]\n",
      "   -------------------- ------------------- 1/2 [edge_tts]\n",
      "   -------------------- ------------------- 1/2 [edge_tts]\n",
      "   ---------------------------------------- 2/2 [edge_tts]\n",
      "\n",
      "Successfully installed edge_tts-7.2.3 tabulate-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install edge_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gradio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01medge_tts\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01masyncio\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gradio'"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import edge_tts\n",
    "import asyncio\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "async def get_voices():\n",
    "    voices = await edge_tts.list_voices()\n",
    "    return {f\"{v['ShortName']} - {v['Locale']} ({v['Gender']})\": v['ShortName'] for v in voices}\n",
    "\n",
    "async def text_to_speech(text, voice, rate, pitch):\n",
    "    if not text.strip():\n",
    "        return None, \"Please enter text to convert.\"\n",
    "    if not voice:\n",
    "        return None, \"Please select a voice.\"\n",
    "    \n",
    "    voice_short_name = voice.split(\" - \")[0]\n",
    "    rate_str = f\"{rate:+d}%\"\n",
    "    pitch_str = f\"{pitch:+d}Hz\"\n",
    "    communicate = edge_tts.Communicate(text, voice_short_name, rate=rate_str, pitch=pitch_str)\n",
    "    \n",
    "    # Save directly to mp3 file (Edge TTS actually outputs mp3 format)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_file:\n",
    "        tmp_path = tmp_file.name\n",
    "        await communicate.save(tmp_path)\n",
    "    \n",
    "    return tmp_path, None\n",
    "\n",
    "async def tts_interface(text, voice, rate, pitch):\n",
    "    audio, warning = await text_to_speech(text, voice, rate, pitch)\n",
    "    if warning:\n",
    "        return audio, gr.Warning(warning)\n",
    "    return audio, None\n",
    "\n",
    "async def create_demo():\n",
    "    voices = await get_voices()\n",
    "    \n",
    "    with gr.Blocks(analytics_enabled=False) as demo:\n",
    "        gr.Markdown(\"# ğŸ™ï¸ Edge TTS Text-to-Speech\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                gr.Markdown(\"## Text-to-Speech with Microsoft Edge TTS\")\n",
    "                gr.Markdown(\"\"\"\n",
    "                Convert text to speech using Microsoft Edge TTS. \n",
    "                Adjust speech rate and pitch: 0 is default, positive values increase, negative values decrease.\n",
    "                \"\"\")\n",
    "                \n",
    "                gr.HTML(\"\"\"\n",
    "                <div style=\"margin: 20px 0; padding: 15px; border: 1px solid #4CAF50; border-radius: 10px; background-color: #f1f8e9;\">\n",
    "                    <p style=\"margin-top: 0;\"><b>Looking for the new version with more features?</b></p>\n",
    "                    <p>The new version includes:</p>\n",
    "                    <ul>\n",
    "                        <li><b>SRT Subtitle Support</b>: Upload SRT files or input SRT format text</li>\n",
    "                        <li><b>File Upload</b>: Easily upload TXT or SRT files</li>\n",
    "                        <li><b>Smart Format Detection</b>: Detects plain text or SRT format</li>\n",
    "                        <li><b>MP3 Output</b>: Generate high-quality MP3 audio</li>\n",
    "                    </ul>\n",
    "                    <div style=\"text-align: center; margin-top: 15px;\">\n",
    "                        <a href=\"https://text-to-speech.wingetgui.com/\" target=\"_blank\" \n",
    "                           style=\"display: inline-block; \n",
    "                                  background: linear-gradient(45deg, #4CAF50, #8BC34A); \n",
    "                                  color: white; \n",
    "                                  padding: 12px 30px; \n",
    "                                  text-decoration: none; \n",
    "                                  border-radius: 30px; \n",
    "                                  font-weight: bold; \n",
    "                                  font-size: 16px;\n",
    "                                  box-shadow: 0 4px 10px rgba(76, 175, 80, 0.3);\n",
    "                                  transition: all 0.3s ease;\">Try New Version â”</a>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\")\n",
    "            \n",
    "            with gr.Column(scale=1):\n",
    "                gr.HTML(\"\"\"\n",
    "                <div style=\"height: 100%; background-color: #f0f8ff; padding: 15px; border-radius: 10px;\">\n",
    "                    <h2 style=\"color: #1e90ff; margin-top: 0;\">Turn Your Text Into Professional Videos!</h2>\n",
    "                    <ul style=\"list-style-type: none; padding-left: 0;\">\n",
    "                        <li>âœ… <b>40+ languages and 300+ voices supported</b></li>\n",
    "                        <li>âœ… <b>Custom backgrounds, music, and visual effects</b></li>\n",
    "                        <li>âœ… <b>Create engaging video content from simple text</b></li>\n",
    "                        <li>âœ… <b>Perfect for educators, content creators, and marketers</b></li>\n",
    "                    </ul>\n",
    "                    <div style=\"text-align: center; margin-top: 20px;\">\n",
    "                        <span style=\"font-size: 96px;\">ğŸ¬</span>\n",
    "                        <div style=\"margin-top: 15px;\">\n",
    "                            <a href=\"https://text2video.wingetgui.com/\" target=\"_blank\" \n",
    "                               style=\"display: inline-block; \n",
    "                                      background: linear-gradient(45deg, #2196F3, #21CBF3); \n",
    "                                      color: white; \n",
    "                                      padding: 12px 30px; \n",
    "                                      text-decoration: none; \n",
    "                                      border-radius: 30px; \n",
    "                                      font-weight: bold; \n",
    "                                      font-size: 16px;\n",
    "                                      box-shadow: 0 4px 10px rgba(33, 150, 243, 0.3);\n",
    "                                      transition: all 0.3s ease;\">Try Text-to-Video â”</a>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\")\n",
    "                \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                text_input = gr.Textbox(label=\"Input Text\", lines=5)\n",
    "                voice_dropdown = gr.Dropdown(choices=[\"\"] + list(voices.keys()), label=\"Select Voice\", value=\"\")\n",
    "                rate_slider = gr.Slider(minimum=-50, maximum=50, value=0, label=\"Speech Rate Adjustment (%)\", step=1)\n",
    "                pitch_slider = gr.Slider(minimum=-20, maximum=20, value=0, label=\"Pitch Adjustment (Hz)\", step=1)\n",
    "                \n",
    "                generate_btn = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
    "                \n",
    "                audio_output = gr.Audio(label=\"Generated Audio\", type=\"filepath\")\n",
    "                warning_md = gr.Markdown(label=\"Warning\", visible=False)\n",
    "                \n",
    "                generate_btn.click(\n",
    "                    fn=tts_interface,\n",
    "                    inputs=[text_input, voice_dropdown, rate_slider, pitch_slider],\n",
    "                    outputs=[audio_output, warning_md]\n",
    "                )\n",
    "        \n",
    "        gr.Markdown(\"Experience the power of Edge TTS for text-to-speech conversion, and explore our advanced Text-to-Video Converter for even more creative possibilities!\")\n",
    "    \n",
    "    return demo\n",
    "\n",
    "async def main():\n",
    "    demo = await create_demo()\n",
    "    demo.queue(default_concurrency_limit=50)\n",
    "    demo.launch(show_api=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Voice ar-AE-FatimaNeural saved successfully! Time taken: 1.61 seconds\n",
      "âœ… Voice ar-AE-HamdanNeural saved successfully! Time taken: 1.14 seconds\n",
      "âœ… Voice ar-BH-AliNeural saved successfully! Time taken: 1.51 seconds\n",
      "âœ… Voice ar-BH-LailaNeural saved successfully! Time taken: 1.33 seconds\n",
      "âœ… Voice ar-DZ-AminaNeural saved successfully! Time taken: 1.51 seconds\n",
      "âœ… Voice ar-DZ-IsmaelNeural saved successfully! Time taken: 1.80 seconds\n",
      "âœ… Voice ar-EG-SalmaNeural saved successfully! Time taken: 1.98 seconds\n",
      "âœ… Voice ar-EG-ShakirNeural saved successfully! Time taken: 2.21 seconds\n",
      "âœ… Voice ar-IQ-BasselNeural saved successfully! Time taken: 1.70 seconds\n",
      "âœ… Voice ar-IQ-RanaNeural saved successfully! Time taken: 1.27 seconds\n",
      "âœ… Voice ar-JO-SanaNeural saved successfully! Time taken: 1.64 seconds\n",
      "âœ… Voice ar-JO-TaimNeural saved successfully! Time taken: 1.73 seconds\n",
      "âœ… Voice ar-KW-FahedNeural saved successfully! Time taken: 1.44 seconds\n",
      "âœ… Voice ar-KW-NouraNeural saved successfully! Time taken: 1.58 seconds\n",
      "âœ… Voice ar-LB-LaylaNeural saved successfully! Time taken: 1.57 seconds\n",
      "âœ… Voice ar-LB-RamiNeural saved successfully! Time taken: 1.91 seconds\n",
      "âœ… Voice ar-LY-ImanNeural saved successfully! Time taken: 1.93 seconds\n",
      "âœ… Voice ar-LY-OmarNeural saved successfully! Time taken: 1.80 seconds\n",
      "âœ… Voice ar-MA-JamalNeural saved successfully! Time taken: 1.36 seconds\n",
      "âœ… Voice ar-MA-MounaNeural saved successfully! Time taken: 3.10 seconds\n",
      "âœ… Voice ar-OM-AbdullahNeural saved successfully! Time taken: 2.55 seconds\n",
      "âœ… Voice ar-OM-AyshaNeural saved successfully! Time taken: 1.90 seconds\n",
      "âœ… Voice ar-QA-AmalNeural saved successfully! Time taken: 1.81 seconds\n",
      "âœ… Voice ar-QA-MoazNeural saved successfully! Time taken: 16.45 seconds\n",
      "âœ… Voice ar-SA-HamedNeural saved successfully! Time taken: 1.75 seconds\n",
      "âœ… Voice ar-SA-ZariyahNeural saved successfully! Time taken: 1.37 seconds\n",
      "âœ… Voice ar-SY-AmanyNeural saved successfully! Time taken: 1.86 seconds\n",
      "âœ… Voice ar-SY-LaithNeural saved successfully! Time taken: 1.97 seconds\n",
      "âœ… Voice ar-TN-HediNeural saved successfully! Time taken: 1.70 seconds\n",
      "âœ… Voice ar-TN-ReemNeural saved successfully! Time taken: 1.92 seconds\n",
      "âœ… Voice ar-YE-MaryamNeural saved successfully! Time taken: 1.74 seconds\n",
      "âœ… Voice ar-YE-SalehNeural saved successfully! Time taken: 1.97 seconds\n"
     ]
    }
   ],
   "source": [
    "# list of voices\n",
    "import asyncio\n",
    "import edge_tts\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Create output directory if not exists\n",
    "output_dir = \"arabicvoices\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    " \n",
    "voices = [ \n",
    "    \"ur-PK-AsadNeural\",\n",
    "    \"ur-PK-UzmaNeural\",\n",
    "   \n",
    "]  # You can add more voices\n",
    "voices = [\n",
    "    \"ar-AE-FatimaNeural\", \"ar-AE-HamdanNeural\", \"ar-BH-AliNeural\",\n",
    "    \"ar-BH-LailaNeural\", \"ar-DZ-AminaNeural\", \"ar-DZ-IsmaelNeural\",\n",
    "    \"ar-EG-SalmaNeural\", \"ar-EG-ShakirNeural\", \"ar-IQ-BasselNeural\",\n",
    "    \"ar-IQ-RanaNeural\", \"ar-JO-SanaNeural\", \"ar-JO-TaimNeural\",\n",
    "    \"ar-KW-FahedNeural\", \"ar-KW-NouraNeural\", \"ar-LB-LaylaNeural\",\n",
    "    \"ar-LB-RamiNeural\", \"ar-LY-ImanNeural\", \"ar-LY-OmarNeural\",\n",
    "    \"ar-MA-JamalNeural\", \"ar-MA-MounaNeural\", \"ar-OM-AbdullahNeural\",\n",
    "    \"ar-OM-AyshaNeural\", \"ar-QA-AmalNeural\", \"ar-QA-MoazNeural\",\n",
    "    \"ar-SA-HamedNeural\", \"ar-SA-ZariyahNeural\", \"ar-SY-AmanyNeural\",\n",
    "    \"ar-SY-LaithNeural\", \"ar-TN-HediNeural\", \"ar-TN-ReemNeural\",\n",
    "    \"ar-YE-MaryamNeural\", \"ar-YE-SalehNeural\"\n",
    "]\n",
    "async def generate_voice(voice_name, text=\"\"\"Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† ØªØ¬Ø±Ø¨Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£ØµÙˆØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©\"\"\"):\n",
    "    \"\"\"Generate speech using the given voice and save it as a file.\"\"\"\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        filename = f\"{output_dir}/{voice_name}.mp3\"\n",
    "        \n",
    "        # Generate voice\n",
    "        tts = edge_tts.Communicate(text, voice=voice_name,volume=\"+100%\",\n",
    "                pitch=\"+10Hz\",\n",
    "                rate=\"-10%\",)\n",
    "        await tts.save(filename)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"âœ… Voice {voice_name} saved successfully! Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error generating voice {voice_name}: {e}\")\n",
    "\n",
    "async def process_voices():\n",
    "    \"\"\"Process voices sequentially to avoid overwhelming the system.\"\"\"\n",
    "    queue = asyncio.Queue()\n",
    "    \n",
    "    # Add voices to queue\n",
    "    for voice in voices:\n",
    "        await queue.put(voice)\n",
    "\n",
    "    while not queue.empty():\n",
    "        voice_name = await queue.get()\n",
    "        await generate_voice(voice_name)\n",
    "        queue.task_done()\n",
    "\n",
    "async def main():\n",
    "    await process_voices()\n",
    "\n",
    "# âœ… Run the async function safely\n",
    "asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
