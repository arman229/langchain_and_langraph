{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 118\u001b[39m\n\u001b[32m    107\u001b[39m scene_data = [\n\u001b[32m    108\u001b[39m     {\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m1\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    109\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mScene\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mSunny Meadow\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m      \u001b[33m'\u001b[39m\u001b[33mSave_image_path\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33marman_output\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mNew_Generated_images\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mimages_20250403064306\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mimage_scene_1.png\u001b[39m\u001b[33m'\u001b[39m},\n\u001b[32m    115\u001b[39m ]\n\u001b[32m    117\u001b[39m output_filename = \u001b[33m\"\u001b[39m\u001b[33mtypewriter_animatiosssssssssn.mp4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[43mcreate_video_with_typewriter_effect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mcreate_video_with_typewriter_effect\u001b[39m\u001b[34m(scene_data, output_filename, fontsize, video_fps)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m image_path:\n\u001b[32m     62\u001b[39m     image = cv2.imread(image_path)\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     image = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     frames = zoom_in(image, num_frames) \u001b[38;5;28;01mif\u001b[39;00m idx % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m zoom_out(image, num_frames)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "def split_text_into_segments(text, font, max_width):\n",
    "    words = text.split()\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "    for word in words:\n",
    "        test_line = current_segment + (\" \" if current_segment else \"\") + word\n",
    "        w = font.getbbox(test_line)[2]\n",
    "        if w <= max_width:\n",
    "            current_segment = test_line\n",
    "        else:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)\n",
    "            current_segment = word\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)\n",
    "    print(f\"print segments: {segments}\")    \n",
    "    return segments\n",
    "\n",
    "def zoom_in(image, num_frames=30, zoom_factor=0.5):\n",
    "    frames = []\n",
    "    h, w = image.shape[:2]\n",
    "    for i in range(num_frames):\n",
    "        scale = 1.0 + (i / num_frames) * zoom_factor\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "        frame = cv2.warpAffine(image, M, (w, h))\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def zoom_out(image, num_frames=30, zoom_factor=0.5):\n",
    "    frames = []\n",
    "    h, w = image.shape[:2]\n",
    "    for i in range(num_frames):\n",
    "        scale = 1.0 + ((num_frames - i - 1) / num_frames) * zoom_factor\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "        frame = cv2.warpAffine(image, M, (w, h))\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def create_video_with_typewriter_effect(scene_data, output_filename, fontsize=60, video_fps=15):\n",
    "    font = ImageFont.truetype(\"arial.ttf\", fontsize)\n",
    "    video_width = 1080\n",
    "    video_height = 1920\n",
    "    video_size = (video_width, video_height)\n",
    "    video = cv2.VideoWriter(output_filename, \n",
    "                            cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                            video_fps, \n",
    "                            video_size)\n",
    "    \n",
    "    for idx, scene in enumerate(scene_data):\n",
    "        narration = scene['Narration']\n",
    "        scene_duration = scene['Audio_duration']\n",
    "        image_path = scene.get('Save_image_path', None)\n",
    "        num_frames = int(scene_duration * video_fps)\n",
    "        \n",
    "        if image_path:\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (video_width, video_height))\n",
    "            frames = zoom_in(image, num_frames) if idx % 2 == 0 else zoom_out(image, num_frames)\n",
    "        else:\n",
    "            frames = [np.zeros((video_height, video_width, 3), dtype=np.uint8) for _ in range(num_frames)]\n",
    "        \n",
    "        segments = split_text_into_segments(narration, font, video_width - 40)\n",
    "        num_segments = len(segments)\n",
    "        if num_segments == 0:\n",
    "            continue\n",
    "        \n",
    "        total_chars = sum(len(segment) for segment in segments)\n",
    "        \n",
    "        # Allocate time to each segment proportionally to its length\n",
    "        for segment in segments:\n",
    "            seg_chars = len(segment)\n",
    "            segment_duration = (seg_chars / total_chars) * scene_duration\n",
    "            segment_frames = int(segment_duration * video_fps)\n",
    "            total_chars_in_segment = len(segment)\n",
    "            for frame_idx in range(segment_frames):\n",
    "                frame = frames[frame_idx % num_frames].copy()\n",
    "                frame_pil = Image.fromarray(frame)\n",
    "                draw = ImageDraw.Draw(frame_pil)\n",
    "                \n",
    "                # Ensure final frame shows full text\n",
    "                char_count = int(((frame_idx + 1) / segment_frames) * total_chars_in_segment)\n",
    "                displayed_text = segment[:char_count]\n",
    "                \n",
    "                text_width, text_height = font.getbbox(displayed_text)[2:4]\n",
    "                x = (video_width - text_width) // 2\n",
    "                y = (video_height - text_height) // 2\n",
    "                \n",
    "                # Draw a black rectangle as background behind the text\n",
    "                padding = 10\n",
    "                rect_coords = [(x - padding, y - padding), (x + text_width + padding, y + text_height + padding)]\n",
    "                draw.rectangle(rect_coords, fill=(0, 0, 0))\n",
    "                \n",
    "                # Now draw the text on top\n",
    "                draw.text((x, y), displayed_text, font=font, fill=(255, 255, 255))\n",
    "                \n",
    "                video.write(np.array(frame_pil))\n",
    "    \n",
    "    video.release()\n",
    "    print(f\"Video saved as {output_filename}\")\n",
    "\n",
    "scene_data = [\n",
    "    {'id': '1',\n",
    "     'Scene': 'Sunny Meadow',\n",
    "     'Description': 'Sunny Meadow where Barnaby and Sheldon meet near the big oak tree.',\n",
    "     'Narration': 'One sunny morning, Barnaby hopped past Sheldon Shelldon, a tortoise whose shell was a beautiful shade of deep green. Sheldon was slowly, slowly making his way to the big oak tree   ',\n",
    "     'Save_audio_path': 'arman_output\\\\New_Generated_voices\\\\voices_20250403064254\\\\voice_scene_1.mp3',\n",
    "     'Audio_duration': 12.55,\n",
    "     'Save_image_path': 'arman_output\\\\New_Generated_images\\\\images_20250403064306\\\\image_scene_1.png'},\n",
    "]\n",
    "\n",
    "output_filename = \"typewriter_animatiosssssssssn.mp4\"\n",
    "create_video_with_typewriter_effect(scene_data, output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Static caption ###########3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from moviepy import *\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import json\n",
    "from typing import Sequence\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from typing import Annotated\n",
    "from IPython.display import display, Markdown\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# ----------------------- Data Types -----------------------\n",
    "class ClassObject(TypedDict):\n",
    "    Object: str\n",
    "    Description: str\n",
    "\n",
    "class MainCharacters(TypedDict):\n",
    "    Name: str\n",
    "    Appearance: str\n",
    "    Characteristics: str\n",
    "\n",
    "class SupportingCharacters(TypedDict):\n",
    "    Name: str\n",
    "    Appearance: str\n",
    "    Characteristics: str\n",
    "\n",
    "class ScenesList(TypedDict):\n",
    "    id: str\n",
    "    Scene: str\n",
    "    Description: str\n",
    "    Narration: str\n",
    "    Img_prompt: str\n",
    "    Save_audio_path: str\n",
    "    Save_image_path: str\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    MainCharacters: list[MainCharacters]\n",
    "    SupportingCharacters: list[SupportingCharacters]\n",
    "    Scene_list: list[ScenesList]\n",
    "    Objects: list[ClassObject]\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    pre_processing_video_path: str\n",
    "    Voices_folder: str\n",
    "    Images_folder: str\n",
    "\n",
    "class SubState(TypedDict):\n",
    "    current_scene: ScenesList\n",
    "    output_folder: str\n",
    "\n",
    "# ----------------------- Utility Functions -----------------------\n",
    "def split_text_into_segments(text, font, max_width):\n",
    "    \"\"\"Split the text into segments that fit within max_width.\"\"\"\n",
    "    words = text.split()\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "    for word in words:\n",
    "        test_line = current_segment + (\" \" if current_segment else \"\") + word\n",
    "        w = font.getbbox(test_line)[2]\n",
    "        if w <= max_width:\n",
    "            current_segment = test_line\n",
    "        else:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)\n",
    "            current_segment = word\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)\n",
    "    print(f\"print segments: {segments}\")    \n",
    "    return segments\n",
    "\n",
    "def zoom_in(image, num_frames=30, zoom_factor=0.5):\n",
    "    \"\"\"Generates frames for a zoom-in effect.\"\"\"\n",
    "    frames = []\n",
    "    h, w = image.shape[:2]\n",
    "    for i in range(num_frames):\n",
    "        scale = 1.0 + (i / num_frames) * zoom_factor\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "        frame = cv2.warpAffine(image, M, (w, h))\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def zoom_out(image, num_frames=30, zoom_factor=0.5):\n",
    "    \"\"\"Generates frames for a zoom-out effect without blinking.\"\"\"\n",
    "    frames = []\n",
    "    h, w = image.shape[:2]\n",
    "    for i in range(num_frames):\n",
    "        scale = 1.0 + ((num_frames - i - 1) / num_frames) * zoom_factor\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, 0, scale)\n",
    "        frame = cv2.warpAffine(image, M, (w, h))\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def fade_in(image, num_frames=2):\n",
    "    \"\"\"Creates a fade-in effect from black to the image.\"\"\"\n",
    "    frames = []\n",
    "    black = np.zeros_like(image)\n",
    "    for i in range(num_frames):\n",
    "        alpha = i / num_frames\n",
    "        frame = cv2.addWeighted(image, alpha, black, 1 - alpha, 0)\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def fade_out(image, num_frames=30):\n",
    "    \"\"\"Creates a fade-out effect from image to black.\"\"\"\n",
    "    frames = []\n",
    "    black = np.zeros_like(image)\n",
    "    for i in range(num_frames):\n",
    "        alpha = 1 - i / num_frames\n",
    "        frame = cv2.addWeighted(image, alpha, black, 1 - alpha, 0)\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "# ----------------------- Pre-processing Video Function -----------------------\n",
    "def pre_processing_video(state: GraphState):\n",
    "    fps = 2\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    dynamic_folder = f\"pre_video_{timestamp}\"\n",
    "    output_folder = os.path.join(\"Pre_Generated_videos\", dynamic_folder)\n",
    "    output_folder = os.path.join(\"output\", output_folder)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    file_name = f'pre_video_{timestamp}.mp4'\n",
    "    \n",
    "    pre_processing_video_path = os.path.join(output_folder, file_name)\n",
    "    scene_list = state['Scene_list']\n",
    "    if not scene_list:\n",
    "        raise ValueError(\"No scenes provided.\")\n",
    "\n",
    "    first_img = cv2.imread(scene_list[0][\"Save_image_path\"])\n",
    "    if first_img is None:\n",
    "        raise ValueError(f\"Cannot load image: {scene_list[0]['Save_image_path']}\")\n",
    "    \n",
    "    h, w, _ = first_img.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    video_writer = cv2.VideoWriter(pre_processing_video_path, fourcc, fps, (w, h))\n",
    "    \n",
    "    # Load a font for captions (adjust size as needed)\n",
    "    caption_font = ImageFont.truetype(\"arial.ttf\", 32)\n",
    "    # Maximum width for caption text (with some margin)\n",
    "    max_caption_width = w - 40\n",
    "    \n",
    "    for idx, scene in enumerate(scene_list):\n",
    "        img_path = scene[\"Save_image_path\"]\n",
    "        duration = float(scene[\"Audio_duration\"])\n",
    "        narration = scene[\"Narration\"]\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Cannot load image {img_path}. Skipping.\")\n",
    "            continue\n",
    "        img = cv2.resize(img, (w, h))\n",
    "        \n",
    "        total_frames = int(fps * duration)\n",
    "        fade_in_frame = int(fps * 1)\n",
    "        fade_out_frame = int(fps * 1)\n",
    "        first_image_duration = total_frames - fade_out_frame\n",
    "        \n",
    "        # Generate zoom/fade effect frames\n",
    "        if idx == 0:\n",
    "            zoom_in_frames = zoom_in(img, num_frames=first_image_duration, zoom_factor=0.5)\n",
    "            final_zoom_frame = zoom_in_frames[-1]\n",
    "            fade_out_frames = fade_out(final_zoom_frame, num_frames=fade_out_frame)\n",
    "            effect_frames = zoom_in_frames + fade_out_frames\n",
    "        elif idx % 2 == 1:\n",
    "            zoom_out_frames = zoom_out(img, num_frames=first_image_duration, zoom_factor=0.5)\n",
    "            final_zoom_frame = zoom_out_frames[-1]\n",
    "            fade_out_frames = fade_out(final_zoom_frame, num_frames=fade_out_frame)\n",
    "            effect_frames = zoom_out_frames + fade_out_frames\n",
    "        else:\n",
    "            fade_in_frames = fade_in(img, num_frames=fade_in_frame)\n",
    "            zoom_in_frames = zoom_in(img, num_frames=first_image_duration, zoom_factor=0.5)\n",
    "            final_zoom_frame = zoom_in_frames[-1]\n",
    "            fade_out_frames = fade_out(final_zoom_frame, num_frames=fade_out_frame)\n",
    "            effect_frames = fade_in_frames + zoom_in_frames + fade_out_frames\n",
    "        \n",
    "        # Use the split_text_into_segments logic to divide the narration into caption segments\n",
    "        segments = split_text_into_segments(narration, caption_font, max_caption_width)\n",
    "        num_segments = len(segments)\n",
    "        if num_segments == 0:\n",
    "            current_caption = \"\"\n",
    "        else:\n",
    "            # Determine frames per caption segment (display each segment for a proportionate time)\n",
    "            frames_per_segment = total_frames // num_segments\n",
    "        \n",
    "        # Overlay the caption on each frame\n",
    "        for frame_idx in range(total_frames):\n",
    "            frame = effect_frames[frame_idx].copy()\n",
    "            frame_pil = Image.fromarray(frame)\n",
    "            draw = ImageDraw.Draw(frame_pil)\n",
    "            \n",
    "            if num_segments > 0:\n",
    "                # Determine current segment index based on frame index\n",
    "                segment_index = min(frame_idx // frames_per_segment, num_segments - 1)\n",
    "                current_caption = segments[segment_index]\n",
    "            else:\n",
    "                current_caption = \"\"\n",
    "            \n",
    "            # Measure text size and calculate position (bottom center with padding)\n",
    "            text_width, text_height = caption_font.getbbox(current_caption)[2:4]\n",
    "            x = (w - text_width) // 2\n",
    "            y = h - text_height - 50  # 50 pixels margin from bottom\n",
    "            \n",
    "            # Draw a black rectangle as a background for the caption text\n",
    "            padding = 10\n",
    "            draw.rectangle([(x - padding, y - padding), (x + text_width + padding, y + text_height + padding)], fill=(0, 0, 0))\n",
    "            # Draw the caption text in white\n",
    "            draw.text((x, y), current_caption, font=caption_font, fill=(255, 255, 255))\n",
    "            \n",
    "            video_writer.write(np.array(frame_pil))\n",
    "    \n",
    "    video_writer.release()\n",
    "    print(f\"pre_processing_video saved as {pre_processing_video_path}\") \n",
    "    state['pre_processing_video_path'] = pre_processing_video_path \n",
    "    return state\n",
    "\n",
    "# ----------------------- Workflow -----------------------\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node('pre_processing_video', pre_processing_video)\n",
    "workflow.add_edge(START, 'pre_processing_video')\n",
    "workflow.add_edge('pre_processing_video', END)\n",
    "app = workflow.compile()\n",
    "\n",
    "# Invoke the workflow with your scene data (assumed to be available in resp3['Scene_list'])\n",
    "resp4 = app.invoke({\"Scene_list\": resp3['Scene_list']})\n",
    "print(resp4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import asyncio\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import random\n",
    "# Fixed resolution and fps\n",
    "TARGET_W, TARGET_H = 720, 1280\n",
    "FPS = 30\n",
    "\n",
    "# Utilities\n",
    "import math\n",
    " \n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, width, height, color=(255, 255, 255), min_size=2, max_size=5):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.color = color\n",
    "        self.min_size = min_size\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        speed_factor = 1.75 \n",
    "        self.x = 0  # Start from left\n",
    "        self.y = random.uniform(0, self.height)  # Random Y position\n",
    "        self.radius = random.uniform(self.min_size, self.max_size)\n",
    "        self.speed_x = random.uniform(3.0, 8.0)*speed_factor  # Strong rightward motion\n",
    "        self.speed_y = random.uniform(-1.0, 1.0)*speed_factor  # Slight up/down\n",
    "        self.alpha = random.randint(50,100)\n",
    "        self.life = random.randint(40, 80)\n",
    "        self.age = 0\n",
    "\n",
    "    def move(self):\n",
    "        self.x += self.speed_x\n",
    "        self.y += self.speed_y\n",
    "        self.age += 1\n",
    "\n",
    "        fade_ratio = 1.0 - (self.age / self.life)\n",
    "        self.alpha = int(self.alpha * fade_ratio)\n",
    "\n",
    "        if self.x > self.width or self.age >= self.life:\n",
    "            self.reset()\n",
    "\n",
    "    def draw(self, draw_obj):\n",
    "        rgba_color = (*self.color, max(0, min(255, self.alpha)))\n",
    "        draw_obj.ellipse(\n",
    "            (self.x, self.y, self.x + self.radius, self.y + self.radius),\n",
    "            fill=rgba_color\n",
    "        )\n",
    "\n",
    "def split_text_into_segments(text: str, font: ImageFont.FreeTypeFont, max_width: int) -> List[str]:\n",
    "    words = text.split()\n",
    "    segments, current = [], \"\"\n",
    "    for w in words:\n",
    "        test = f\"{current} {w}\".strip()\n",
    "        width = font.getbbox(test)[2]\n",
    "        if width <= max_width:\n",
    "            current = test\n",
    "        else:\n",
    "            if current:\n",
    "                segments.append(current)\n",
    "            current = w\n",
    "    if current:\n",
    "        segments.append(current)\n",
    "    return segments\n",
    "\n",
    "# Effects\n",
    "\n",
    "def zoom_in(img, frames, zoom):\n",
    "    h, w = img.shape[:2]\n",
    "    out = []\n",
    "    for i in range(frames):\n",
    "        scale = 1 + (i/frames)*zoom\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), 0, scale)\n",
    "        out.append(cv2.warpAffine(img, M, (w, h)))\n",
    "    return out\n",
    "\n",
    "def zoom_out(img, frames, zoom):\n",
    "    h, w = img.shape[:2]\n",
    "    out = []\n",
    "    for i in range(frames):\n",
    "        scale = 1 + ((frames-i-1)/frames)*zoom\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), 0, scale)\n",
    "        out.append(cv2.warpAffine(img, M, (w, h)))\n",
    "    return out\n",
    "\n",
    "def fade_in(seq, fade):\n",
    "    black = np.zeros_like(seq[0])\n",
    "    out = []\n",
    "    for i in range(fade):\n",
    "        alpha = (i+1)/fade\n",
    "        out.append(cv2.addWeighted(seq[0], alpha, black, 1-alpha, 0))\n",
    "    return out + seq\n",
    "\n",
    "def fade_out(seq, fade):\n",
    "    black = np.zeros_like(seq[0])\n",
    "    out = []\n",
    "    for i in range(fade):\n",
    "        alpha = 1 - (i+1)/fade\n",
    "        out.append(cv2.addWeighted(seq[-1], alpha, black, 1-alpha, 0))\n",
    "    return seq + out\n",
    "\n",
    " \n",
    "async def single_video_generation(cur_scene, output_folder: str, ctx):\n",
    "    \n",
    "    narration = cur_scene.narration\n",
    "    img_path = cur_scene.image_path\n",
    "    \n",
    "    audio_dur = float(cur_scene.audio_duration)\n",
    "    fade_frames = int(0.5 * FPS)\n",
    "    audio_frames     = math.ceil(audio_dur * FPS)\n",
    "    zoom_frame=0.5\n",
    "    \n",
    "           \n",
    "          \n",
    "    total_video_frames = audio_frames + 2 * fade_frames\n",
    "    core_frames      = audio_frames \n",
    "     \n",
    "     \n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Cannot load image: {img_path}\")\n",
    "    img = cv2.resize(img, (TARGET_W, TARGET_H))\n",
    "\n",
    "    \n",
    "    \n",
    "     \n",
    "    sid = int(cur_scene.id)\n",
    "    if  sid % 2 != 0:\n",
    "        core_seq = zoom_in(img, core_frames,zoom_frame)\n",
    "    else:\n",
    "        core_seq = zoom_out(img, core_frames, zoom_frame)\n",
    "\n",
    "    seq = fade_out(fade_in(core_seq, fade_frames), fade_frames)\n",
    "\n",
    "    if sid == 1:\n",
    "        seq = fade_out(core_seq, fade_frames)\n",
    "    else:\n",
    "        seq = fade_out(fade_in(core_seq, fade_frames), fade_frames)\n",
    "        \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    out_path = os.path.join(output_folder, f\"video_scene_{sid}.mp4\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, FPS, (TARGET_W, TARGET_H))\n",
    "\n",
    "    \n",
    "            \n",
    "    font = ImageFont.truetype(\"arial.ttf\", 40)\n",
    "    max_w = TARGET_W - 40\n",
    "    segments = split_text_into_segments(narration, font, max_w)\n",
    "    if not segments:\n",
    "        segments = [\"\"]\n",
    "    total_chars = sum(len(s) for s in segments)\n",
    "    \n",
    "    if sid != 1:\n",
    "        for f in range(fade_frames):\n",
    "            writer.write(seq[f])\n",
    "    caption_idx = 0\n",
    "     \n",
    "    num_particles = 20\n",
    "    particle_color = (255, 255, 255)   \n",
    "    particles = [Particle(TARGET_W, TARGET_H, color=particle_color, min_size=1, max_size=4) for _ in range(num_particles)]\n",
    "    for seg in segments:\n",
    "        seg_chars  = len(seg)\n",
    "        seg_frames = max(1, int((seg_chars / total_chars) * audio_frames))\n",
    "        for i in range(seg_frames):\n",
    "            abs_frame = (0 if sid == 1 else fade_frames) + caption_idx\n",
    "            if abs_frame >= len(seq):\n",
    "                break\n",
    "\n",
    "            frame   = seq[abs_frame].copy()\n",
    "            img_pil = Image.fromarray(frame)\n",
    "            draw    = ImageDraw.Draw(img_pil)\n",
    "            for p in particles:\n",
    "                p.draw(draw)\n",
    "                p.move()\n",
    "            # Partial text reveal\n",
    "            count = int(((i+1) / seg_frames) * seg_chars)\n",
    "            text  = seg[:count]\n",
    "            tw, th = font.getbbox(text)[2:4]\n",
    "            x = (TARGET_W - tw) // 2\n",
    "            y = (TARGET_H - th) // 2\n",
    "\n",
    "            # Draw background box + text\n",
    "            pad = 10\n",
    "            draw.rectangle([(x-pad,y-pad),(x+tw+pad,y+th+pad)], fill=(0,0,0))\n",
    "            draw.text((x,y), text, font=font, fill=(255,255,255))\n",
    "\n",
    "            writer.write(np.array(img_pil))\n",
    "            caption_idx += 1\n",
    "    \n",
    "    start_fade_out = (0 if sid == 1 else fade_frames) + audio_frames\n",
    "    for f in range(fade_frames):\n",
    "        if start_fade_out + f < len(seq):\n",
    "            writer.write(seq[start_fade_out + f])\n",
    "\n",
    "    writer.release()\n",
    "\n",
    "    \n",
    "    for s in ctx.scene_list:\n",
    "        if s.id == cur_scene.id:\n",
    "            s.video_path = out_path\n",
    "            break\n",
    "    return out_path\n",
    "\n",
    "async def continue_generate_video(scenes_resp, output_folder,ctx):\n",
    "    tasks = [single_video_generation(scene, output_folder, ctx) for scene in scenes_resp.scene_list[0:1]]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "scenes_resp = VideoGen(\n",
    "    story_theme=\"A boy in a jungle with his cat and dog\",\n",
    "    scene_list=[\n",
    "        ScenesList(\n",
    "            id=\"1\",\n",
    "            scene=\"Jungle Discovery\",\n",
    "            description=\"Leo, Whiskers, and Buddy stumble upon a hidden waterfall in the jungle.\",\n",
    "            narration=\"Once upon a time, Leo and Luna swung through the jungle, laughing as they went!\",\n",
    "            img_prompt=\"Create a detailed, photorealistic image of the following scene:\\n            Leo, Whiskers, and Buddy stumble upon a hidden waterfall in the jungle.\\n\\n            **Main Characters**:\\n            Leo - A young boy, around 7 years old, with messy brown hair, bright green eyes, and always wears a slightly oversized khaki shirt and shorts. Often has dirt smudges on his face and knees., Adventurous, curious, kind-hearted, a little clumsy, loves animals.\\n            **Supporting Characters**:\\n            Whiskers - A fluffy, calico cat with striking green eyes and a perpetually curious expression. Has a habit of getting into things. - Independent, playful, loyal, sometimes mischievous, loves to explore., Buddy - A golden retriever with floppy ears, a wagging tail, and a goofy grin. Wears a red collar. - Friendly, loyal, enthusiastic, protective of Leo, loves to play fetch.\\n            **Objects**:\\n            Lush green jungle foliage, tall trees, a clear waterfall cascading into a small pool, colorful butterflies fluttering around.\\n            **Mood & Lighting**: Cinematic, immersive atmosphere with realistic lighting to match the scene's emotions.\\n            The illustration should capture the story’s essence and atmosphere.\",\n",
    "            object_description=None,\n",
    "            audio_path=\"youtube_shorts/Generated_voices\\\\voices_20250509233133\\\\voice_scene_1.mp3\",\n",
    "            image_path=\"youtube_shorts/Generated_images\\\\images_20250509233133/image_1.png\",\n",
    "            video_path=\"youtube_shorts/Generated_videos\\\\video_20250509233133/video_scene_1.mp4\",\n",
    "            combine_audiovideo_path=\"youtube_shorts/Generated_audio_video\\\\audio_with_video_20250509233133\\\\combine_audio_video_1.mp4\",\n",
    "            audio_duration=6.17,\n",
    "        ),\n",
    "        ScenesList(\n",
    "            id=\"2\",\n",
    "            scene=\"Whiskers' Curiosity\",\n",
    "            description=\"Whiskers gets distracted by a brightly colored butterfly and wanders off.\",\n",
    "            narration=\"Uh oh! They took a wrong turn. Now Leo and Luna are lost!\",\n",
    "            img_prompt=\"Create a detailed, photorealistic image of the following scene:\\n            Whiskers gets distracted by a brightly colored butterfly and wanders off.\\n\\n            **Main Characters**:\\n            Leo - A young boy, around 7 years old, with messy brown hair, bright green eyes, and always wears a slightly oversized khaki shirt and shorts. Often has dirt smudges on his face and knees., Adventurous, curious, kind-hearted, a little clumsy, loves animals.\\n            **Supporting Characters**:\\n            Whiskers - A fluffy, calico cat with striking green eyes and a perpetually curious expression. Has a habit of getting into things. - Independent, playful, loyal, sometimes mischievous, loves to explore., Buddy - A golden retriever with floppy ears, a wagging tail, and a goofy grin. Wears a red collar. - Friendly, loyal, enthusiastic, protective of Leo, loves to play fetch.\\n            **Objects**:\\n            A large fern with broad leaves, a bright blue butterfly, sunlight filtering through the leaves.\\n            **Mood & Lighting**: Cinematic, immersive atmosphere with realistic lighting to match the scene's emotions.\\n            The illustration should capture the story’s essence and atmosphere.\",\n",
    "            object_description=None,\n",
    "            audio_path=\"youtube_shorts/Generated_voices\\\\voices_20250509233133\\\\voice_scene_2.mp3\",\n",
    "            image_path=\"youtube_shorts/Generated_images\\\\images_20250509233133/image_2.png\",\n",
    "            video_path=\"youtube_shorts/Generated_videos\\\\video_20250509233133/video_scene_2.mp4\",\n",
    "            combine_audiovideo_path=\"youtube_shorts/Generated_audio_video\\\\audio_with_video_20250509233133\\\\combine_audio_video_2.mp4\",\n",
    "            audio_duration=6.86,\n",
    "        ),\n",
    "        ScenesList(\n",
    "            id=\"3\",\n",
    "            scene=\"Lost in the Jungle\",\n",
    "            description=\"Leo and Buddy search for Whiskers, calling her name.\",\n",
    "            narration=\"An Old Monkey appears! He is wise and offers to help them find their way.\",\n",
    "            img_prompt=\"Create a detailed, photorealistic image of the following scene:\\n            Leo and Buddy search for Whiskers, calling her name.\\n\\n            **Main Characters**:\\n            Leo - A young boy, around 7 years old, with messy brown hair, bright green eyes, and always wears a slightly oversized khaki shirt and shorts. Often has dirt smudges on his face and knees., Adventurous, curious, kind-hearted, a little clumsy, loves animals.\\n            **Supporting Characters**:\\n            Whiskers - A fluffy, calico cat with striking green eyes and a perpetually curious expression. Has a habit of getting into things. - Independent, playful, loyal, sometimes mischievous, loves to explore., Buddy - A golden retriever with floppy ears, a wagging tail, and a goofy grin. Wears a red collar. - Friendly, loyal, enthusiastic, protective of Leo, loves to play fetch.\\n            **Objects**:\\n            Dense jungle undergrowth, tangled vines, dappled sunlight on the forest floor.\\n            **Mood & Lighting**: Cinematic, immersive atmosphere with realistic lighting to match the scene's emotions.\\n            The illustration should capture the story’s essence and atmosphere.\",\n",
    "            object_description=None,\n",
    "            audio_path=\"youtube_shorts/Generated_voices\\\\voices_20250509233133\\\\voice_scene_3.mp3\",\n",
    "            image_path=\"youtube_shorts/Generated_images\\\\images_20250509233133/image_3.png\",\n",
    "            video_path=\"youtube_shorts/Generated_videos\\\\video_20250509233133/video_scene_3.mp4\",\n",
    "            combine_audiovideo_path=\"youtube_shorts/Generated_audio_video\\\\audio_with_video_20250509233133\\\\combine_audio_video_3.mp4\",\n",
    "            audio_duration=6.53,\n",
    "        ),\n",
    "        ScenesList(\n",
    "            id=\"4\",\n",
    "            scene=\"Reunion\",\n",
    "            description=\"Buddy finds Whiskers stuck in a hollow log, and Leo helps her out.\",\n",
    "            narration=\"Following Old Monkey, Leo and Luna travelled through winding paths to find home.\",\n",
    "            img_prompt=\"Create a detailed, photorealistic image of the following scene:\\n            Buddy finds Whiskers stuck in a hollow log, and Leo helps her out.\\n\\n            **Main Characters**:\\n            Leo - A young boy, around 7 years old, with messy brown hair, bright green eyes, and always wears a slightly oversized khaki shirt and shorts. Often has dirt smudges on his face and knees., Adventurous, curious, kind-hearted, a little clumsy, loves animals.\\n            **Supporting Characters**:\\n            Whiskers - A fluffy, calico cat with striking green eyes and a perpetually curious expression. Has a habit of getting into things. - Independent, playful, loyal, sometimes mischievous, loves to explore., Buddy - A golden retriever with floppy ears, a wagging tail, and a goofy grin. Wears a red collar. - Friendly, loyal, enthusiastic, protective of Leo, loves to play fetch.\\n            **Objects**:\\n            A hollow log covered in moss, Whiskers looking scared, Buddy wagging his tail.\\n            **Mood & Lighting**: Cinematic, immersive atmosphere with realistic lighting to match the scene's emotions.\\n            The illustration should capture the story’s essence and atmosphere.\",\n",
    "            object_description=None,\n",
    "            audio_path=\"youtube_shorts/Generated_voices\\\\voices_20250509233133\\\\voice_scene_4.mp3\",\n",
    "            image_path=\"youtube_shorts/Generated_images\\\\images_20250509233133/image_4.png\",\n",
    "            video_path=\"youtube_shorts/Generated_videos\\\\video_20250509233133/video_scene_4.mp4\",\n",
    "            combine_audiovideo_path=\"youtube_shorts/Generated_audio_video\\\\audio_with_video_20250509233133\\\\combine_audio_video_4.mp4\",\n",
    "            audio_duration=6.17,\n",
    "        ),\n",
    "    ],\n",
    "    supporting_characters=[],\n",
    "    main_characters=[],\n",
    "    final_path=None,\n",
    ")\n",
    "\n",
    "\n",
    "ctx = scenes_resp\n",
    "import time\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    audio_with_video = os.path.join(\n",
    "        \"youtube_shorts/Generated_videos\", f\"video_20250509233133d5\"\n",
    "    )\n",
    "    os.makedirs(audio_with_video, exist_ok=True)\n",
    "    print(audio_with_video)\n",
    "    asyncio.run(continue_generate_video(scenes_resp, audio_with_video, ctx))\n",
    "    print(f\"ctx:{ctx}\")\n",
    "    print(\"text\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
