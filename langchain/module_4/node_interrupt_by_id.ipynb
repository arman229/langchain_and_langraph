{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START,END,StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import display,Image\n",
    "from langchain_core.messages import HumanMessage,SystemMessage,RemoveMessage\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph import add_messages\n",
    "from typing import Annotated\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",api_key=''  )\n",
    "\n",
    "\n",
    "def multiply(a:int, b:int)->int:\n",
    "    \"\"\"Multiply a and b\n",
    "\n",
    "    Args:\n",
    "    a : First number\n",
    "    b : Second number\n",
    "\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "def divide(a:int, b:int)->float:\n",
    "    \"\"\"Divide a and b\n",
    "\n",
    "    Args:\n",
    "    a : First number\n",
    "    b : Second number\n",
    "\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "def add(a:int, b:int)->int:\n",
    "    \"\"\"Add a and b\n",
    "\n",
    "    Args:\n",
    "    a : First number\n",
    "    b : Second number\n",
    "\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subtract(a:int, b:int)->int:\n",
    "    \"\"\"Subtract a and b\n",
    "\n",
    "    Args:\n",
    "    a : First number\n",
    "    b : Second number\n",
    "\n",
    "    \"\"\"\n",
    "    return a - b\n",
    "tools = [add, subtract, divide,multiply]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState,StateGraph,START\n",
    "from langgraph.prebuilt import ToolNode,tools_condition\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import display,Image\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "class CustomState(TypedDict):\n",
    "  messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "sys_message = SystemMessage(content='You are a helpful assistant tasked with performing arthemtic on a set of inputs')\n",
    "def assistant_node(state:CustomState,config:RunnableConfig):\n",
    "    return {'messages':[llm_with_tools.invoke([sys_message] + state['messages'])]}\n",
    "\n",
    "def verifier_node(state:CustomState):\n",
    "\n",
    "  current_state = compiling_graph.get_state(config1)\n",
    "  existingMessages = current_state.values[\"messages\"]\n",
    "  if isinstance(existingMessages[-1],HumanMessage):\n",
    "    lastMessageId = existingMessages[-1].id\n",
    "    newMessage = HumanMessage(content='multiply 7 with 100',id = lastMessageId)\n",
    "    finalMessages = add_messages(existingMessages,newMessage)\n",
    "    compiling_graph.update_state(config1,{\"messages\":finalMessages})\n",
    "    pass\n",
    "\n",
    "building_graph = StateGraph(CustomState)\n",
    "building_graph.add_node('verifier',verifier_node)\n",
    "building_graph.add_node('assistant',assistant_node)\n",
    "building_graph.add_node('tools',ToolNode(tools))\n",
    "\n",
    "building_graph.add_edge(START,'verifier')\n",
    "building_graph.add_edge('verifier','assistant')\n",
    "building_graph.add_conditional_edges('assistant',tools_condition)\n",
    "building_graph.add_edge('tools','assistant')\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "compiling_graph = building_graph.compile(checkpointer=memory, interrupt_before=[\"verifier\"] )\n",
    "\n",
    "display(Image(compiling_graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config1 = {'configurable':{'thread_id':'1',\"user_id\":123}}\n",
    "input = {'messages':[HumanMessage(content='multiply 7 with 10')]}\n",
    "x = compiling_graph.invoke(input,config1)\n",
    "for message in x['messages']:\n",
    "   message.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "current_state = compiling_graph.get_state(config1)\n",
    "existingMessages = current_state.values[\"messages\"]  #f616fd5b-712c-4e35-939a-bb9a514893fd\n",
    "if isinstance(existingMessages[-1],HumanMessage):\n",
    "  lastMessageId = existingMessages[-1].id\n",
    "  newMessage = HumanMessage(content='multiply 7 with 100',id = lastMessageId)\n",
    "  finalMessages = add_messages(existingMessages,newMessage)\n",
    "  compiling_graph.update_state(config1,{\"messages\":finalMessages})\n",
    "\n",
    "\n",
    "for message in compiling_graph.get_state(config1).values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=compiling_graph.invoke(None,config1)\n",
    "for message in x['messages']:\n",
    "    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
