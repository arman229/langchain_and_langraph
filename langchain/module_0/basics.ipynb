{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
      "metadata": {
        "id": "ef597741-3211-4ecc-92f7-f58023ee237e"
      },
      "source": [
        "# LangChain Academy\n",
        "\n",
        "Welcome to LangChain Academy!\n",
        "\n",
        "## Context\n",
        "\n",
        "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible.\n",
        "\n",
        "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state.\n",
        "\n",
        "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
        "\n",
        "## Course Structure\n",
        "\n",
        "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independent of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
        "\n",
        "## Setup\n",
        "\n",
        "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
        "\n",
        "## Chat models\n",
        "\n",
        "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! By default, the course with use [GEMINI_API_KEY](https://ai.google.dev/gemini-api/docs/api-key/) because it is both popular and performant. As noted, please ensure that you have an `GEMINI_API_KEY`.\n",
        "\n",
        "Let's check that your `GEMINI_API_KEY` is set and, if not, you will be asked to enter it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gImZnlolNSEI",
      "metadata": {
        "id": "gImZnlolNSEI"
      },
      "source": [
        "The `%%capture` magic command in Jupyter notebooks is used to capture the output of a cell and suppress the display of output in the notebook. It can be especially useful when you want to suppress standard output (stdout) and error messages (stderr) from being displayed.\n",
        "\n",
        "### **Explanation of the components**:\n",
        "- `%%capture`: This is a cell magic command. It captures the output of all code in the cell, including standard output and standard error, and stores it in a variable or simply suppresses it.\n",
        "- `--no-stderr`: This is an optional flag that tells Jupyter to capture only the standard output (stdout) and **not** the standard error (stderr). If there are errors in the code, they won't be captured or suppressed, and they will still be shown in the output.\n",
        "\n",
        "### **Usage Example**:\n",
        "\n",
        "```python\n",
        "%%capture --no-stderr\n",
        "print(\"This is a normal output.\")\n",
        "raise ValueError(\"This is an error message.\")\n",
        "```\n",
        "\n",
        "In this example:\n",
        "- The **normal output** (`print(\"This is a normal output.\")`) would be captured and suppressed.\n",
        "- The **error message** (`ValueError(\"This is an error message.\")`) would still be shown because the `--no-stderr` flag is used, which ensures errors are not suppressed.\n",
        "\n",
        "### **What happens with the captured output?**\n",
        "If you want to access the captured output later, you can store it in a variable:\n",
        "\n",
        "```python\n",
        "%%capture captured_output\n",
        "print(\"This will be captured.\")\n",
        "```\n",
        "\n",
        "You can then retrieve and use the captured output:\n",
        "\n",
        "```python\n",
        "captured_output.show()  # This will display the captured output\n",
        "```\n",
        "\n",
        "### **Summary**:\n",
        "- `%%capture` suppresses output in Jupyter notebooks.\n",
        "- `--no-stderr` ensures that **only standard output (stdout)** is captured, and **standard error (stderr)** is shown.\n",
        "- It is useful when you want to prevent clutter in your notebook, especially for commands or code that produce unnecessary output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "44144dbe",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture output --no-stderr\n",
        "# Standard output: will be captured\n",
        "print(\"This is a normal message.\")\n",
        "\n",
        "# # Standard error: will not be captured\n",
        "# raise ValueError(\"This is an error message!\")  # This simulates an error\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "41b09b6e",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "This is an error!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a normal output.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is an error!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: This is an error!"
          ]
        }
      ],
      "source": [
        "%%capture output\n",
        "print(\"This is a normal output.\")\n",
        " \n",
        "raise ValueError(\"This is an error!\")\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "e272fc21",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture output --no-stderr\n",
        "print(\"This is a normal output.\")\n",
        "\n",
        " \n",
        "# raise ValueError(\"This is an error!\")\n",
        "\n",
        "# Access captured outputs\n",
        "print(output.stdout)  \n",
        "print(output.stderr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "37d9befb",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture output --no-stderr\n",
        "print(\"This is standard output.\")\n",
        "import sys\n",
        "print(\"This is an error message.\", file=sys.stderr)\n",
        "print(\"This is correct output.\")\n",
        " \n",
        "print(output.stdout)   \n",
        "print(output.stderr)   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "c2227ca5",
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -U  numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "0f9a52c8",
      "metadata": {
        "id": "0f9a52c8"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "!pip install -q langchain_google_genai langchain_core langchain_community tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "628705dc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tavily_API_KEY is loaded successfully\n",
            "GEMINI_API_KEY is loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        " \n",
        "API_KEY = os.getenv( \"GEMINI_API_KEY\")\n",
        "Tavily_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "if not Tavily_API_KEY:\n",
        "    raise ValueError(\"Tavily_API_KEY is not set in the .env file please write api key and proceed further\")\n",
        "\n",
        "print(\"Tavily_API_KEY is loaded successfully\")\n",
        "if not API_KEY:\n",
        "    raise valueError(\"GEMINI_API_KEY is not set in the .env file please write api key and proceed further\")\n",
        "print(\"GEMINI_API_KEY is loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6863b2e8",
      "metadata": {},
      "source": [
        "Note:Temperature in LLMs controls the randomness of responses. Low temperature ensures predictable outputs, while high temperature encourages creativity and diverse responses.\n",
        "In the HumanMessage and AIMessage classes from langchain_core, the name attribute is used to identify the sender of the message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "EfHd5vlIHKd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfHd5vlIHKd8",
        "outputId": "5f010fa0-5b2c-412a-a0ec-01e5d0f08709"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI \n",
        "llm:ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(api_key=API_KEY,model='gemini-1.5-flash',temperature=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "841a9718",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Hi there! How can I help you today?\\n' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-48bef86a-4e35-4584-8049-580dae806886-0' usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "result = llm.invoke(\"hi\")\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c08c501f",
      "metadata": {},
      "outputs": [],
      "source": [
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "a6e34708",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "message_list = [HumanMessage(content=\"hi\", name = \"arman\"),\n",
        "                AIMessage(content=\"AI is a tool for building helpful, accurate, and unbiased AI systems.\", name = \"AI Assistant\"),\n",
        "                HumanMessage(content=\"What are some AI applications?\", name = \"arman\")]\n",
        "result2 = llm.invoke(message_list)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "89afecf0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI applications are incredibly diverse and span many industries. Here are some examples, categorized for clarity:\n",
            "\n",
            "**1. Healthcare:**\n",
            "\n",
            "* **Diagnosis and Treatment:** AI can analyze medical images (X-rays, CT scans, MRIs) to detect diseases like cancer earlier and more accurately than humans alone.  It can also assist in personalized medicine by tailoring treatments based on a patient's genetic makeup and medical history.\n",
            "* **Drug Discovery and Development:** AI accelerates the process of identifying potential drug candidates and predicting their effectiveness, significantly reducing the time and cost of bringing new drugs to market.\n",
            "* **Robotic Surgery:** AI-powered robots assist surgeons with increased precision and minimally invasive procedures.\n",
            "* **Patient Monitoring:** AI systems can analyze patient data (vital signs, medical records) to identify potential problems and alert healthcare providers.\n",
            "\n",
            "**2. Finance:**\n",
            "\n",
            "* **Fraud Detection:** AI algorithms analyze transactions to identify fraudulent activities in real-time.\n",
            "* **Algorithmic Trading:** AI-powered systems execute trades at optimal times based on market analysis.\n",
            "* **Risk Management:** AI helps assess and manage financial risks more effectively.\n",
            "* **Customer Service:** AI-powered chatbots provide instant customer support and answer frequently asked questions.\n",
            "\n",
            "**3. Transportation:**\n",
            "\n",
            "* **Self-Driving Cars:** AI is the core technology behind autonomous vehicles, enabling them to navigate roads and make driving decisions.\n",
            "* **Traffic Optimization:** AI algorithms analyze traffic patterns to optimize traffic flow and reduce congestion.\n",
            "* **Logistics and Supply Chain Management:** AI improves efficiency in transportation and delivery by optimizing routes and predicting demand.\n",
            "\n",
            "**4. Retail and E-commerce:**\n",
            "\n",
            "* **Personalized Recommendations:** AI suggests products and services tailored to individual customer preferences.\n",
            "* **Inventory Management:** AI optimizes inventory levels to minimize waste and ensure sufficient stock.\n",
            "* **Chatbots for Customer Service:** AI-powered chatbots handle customer inquiries and provide support.\n",
            "* **Price Optimization:** AI algorithms determine optimal pricing strategies to maximize revenue.\n",
            "\n",
            "**5. Manufacturing:**\n",
            "\n",
            "* **Predictive Maintenance:** AI predicts equipment failures and schedules maintenance to prevent downtime.\n",
            "* **Quality Control:** AI systems analyze products to identify defects and ensure quality standards are met.\n",
            "* **Robotics and Automation:** AI-powered robots perform repetitive tasks, increasing efficiency and productivity.\n",
            "\n",
            "**6. Other Applications:**\n",
            "\n",
            "* **Natural Language Processing (NLP):**  Used in chatbots, language translation, sentiment analysis, and text summarization.\n",
            "* **Computer Vision:** Used in image recognition, object detection, and facial recognition.\n",
            "* **Education:** Personalized learning platforms adapt to individual student needs.\n",
            "* **Security:** AI enhances cybersecurity by detecting and preventing threats.\n",
            "\n",
            "\n",
            "This is not an exhaustive list, but it provides a broad overview of the diverse applications of AI across various sectors.  The field is constantly evolving, and new applications are emerging all the time.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(result2.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "7LRBkQ3aIrwt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LRBkQ3aIrwt",
        "outputId": "a6aa186d-54e3-4c68-b2f5-29ff9bae81fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'AI applications are incredibly diverse and span many industries. Here are some examples, categorized for clarity:\\n\\n**Everyday Life & Consumer Applications:**\\n\\n* **Smart Assistants (Siri, Alexa, Google Assistant):**  Voice-activated assistants that can answer questions, set reminders, control smart home devices, and more.\\n* **Recommendation Systems (Netflix, Spotify, Amazon):**  Algorithms that suggest movies, music, products, etc., based on user preferences and behavior.\\n* **Spam Filters:**  AI-powered filters that identify and block unwanted emails.\\n* **Image Recognition (Google Photos):**  Automatically tagging and organizing photos based on their content.\\n* **Navigation Apps (Google Maps, Waze):**  Using AI for real-time traffic updates and optimal route planning.\\n* **Fraud Detection:**  Identifying fraudulent transactions in banking and credit card systems.\\n* **Personalized Advertising:**  Targeting ads based on user demographics, interests, and online behavior.\\n\\n\\n**Business & Industry Applications:**\\n\\n* **Customer Service Chatbots:**  Automated systems that answer customer queries and provide support.\\n* **Predictive Maintenance:**  Predicting equipment failures in manufacturing and other industries to prevent downtime.\\n* **Supply Chain Optimization:**  Improving efficiency and reducing costs in logistics and supply chain management.\\n* **Risk Management:**  Assessing and mitigating risks in finance, insurance, and other sectors.\\n* **Medical Diagnosis:**  Assisting doctors in diagnosing diseases and recommending treatments.\\n* **Drug Discovery:**  Accelerating the process of developing new drugs and therapies.\\n* **Financial Modeling:**  Predicting market trends and managing investment portfolios.\\n* **Autonomous Vehicles:**  Self-driving cars and trucks.\\n\\n\\n**Scientific & Research Applications:**\\n\\n* **Climate Modeling:**  Simulating climate change and predicting its effects.\\n* **Genomics and Bioinformatics:**  Analyzing large datasets of genomic information to understand diseases and develop new treatments.\\n* **Astronomy:**  Analyzing astronomical data to discover new planets and galaxies.\\n* **Materials Science:**  Discovering new materials with desired properties.\\n\\n\\nThis is not an exhaustive list, but it gives a good overview of the breadth of AI applications.  New applications are constantly emerging as the technology continues to advance.\\n'"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "message_list = [HumanMessage(content=\"hi\", name = \"arman\"),\n",
        "                AIMessage(content=\"AI is a tool for building helpful, accurate, and unbiased AI systems.\", name = \"AI Assistant\"),\n",
        "                HumanMessage(content=\"What are some AI applications?\", name = \"arman\")]\n",
        "llm.invoke(message_list).content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "82eee5b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI\n",
            " applications are incredibly diverse and span many industries. Here are some examples, categorized for\n",
            " clarity:\n",
            "\n",
            "**1. Healthcare:**\n",
            "\n",
            "* **Diagnosis and Treatment:** AI\n",
            " can analyze medical images (X-rays, CT scans, MRIs) to detect diseases like cancer earlier and more accurately than humans alone.  It can also\n",
            " assist in personalized medicine by tailoring treatments based on individual patient data.\n",
            "* **Drug Discovery and Development:** AI accelerates the process of identifying potential drug candidates and predicting\n",
            " their efficacy and safety, significantly reducing the time and cost involved.\n",
            "* **Robotic Surgery:** AI-powered robots assist surgeons with greater precision and minimally invasive procedures.\n",
            "* **Patient Monitoring:** AI systems can analyze patient data (vital\n",
            " signs, medical history) to predict potential health problems and alert medical staff.\n",
            "\n",
            "**2. Finance:**\n",
            "\n",
            "* **Fraud Detection:** AI algorithms identify fraudulent transactions in real-time, protecting financial institutions and customers.\n",
            "* **Algorithmic\n",
            " Trading:** AI-powered systems execute trades at optimal times, maximizing returns and minimizing risks.\n",
            "* **Risk Management:** AI assesses and manages various financial risks, including credit risk and market risk.\n",
            "* **Customer Service:** AI-powered chatbots provide instant customer support and answer frequently asked questions.\n",
            "\n",
            "**3.\n",
            " Transportation:**\n",
            "\n",
            "* **Self-Driving Cars:** AI is the core technology behind autonomous vehicles, enabling them to navigate roads and make driving decisions.\n",
            "* **Traffic Optimization:** AI algorithms analyze traffic patterns to optimize traffic flow and reduce congestion.\n",
            "* **Logistics and Supply Chain Management:** AI improves efficiency in transportation and delivery\n",
            " by optimizing routes and predicting demand.\n",
            "\n",
            "**4. Retail and E-commerce:**\n",
            "\n",
            "* **Personalized Recommendations:** AI suggests products and services tailored to individual customer preferences.\n",
            "* **Chatbots for Customer Service:** AI-powered chatbots handle customer inquiries and provide support.\n",
            "* **Inventory Management:** AI optimizes\n",
            " inventory levels to minimize waste and ensure sufficient stock.\n",
            "* **Demand Forecasting:** AI predicts future demand for products, helping retailers make informed decisions about inventory and pricing.\n",
            "\n",
            "**5. Manufacturing:**\n",
            "\n",
            "* **Predictive Maintenance:** AI analyzes sensor data from machinery to predict potential failures and schedule maintenance proactively.\n",
            "* **\n",
            "Quality Control:** AI systems identify defects in products during the manufacturing process.\n",
            "* **Robotics and Automation:** AI-powered robots automate various manufacturing tasks, increasing efficiency and productivity.\n",
            "\n",
            "**6. Other Applications:**\n",
            "\n",
            "* **Natural Language Processing (NLP):**  Used in chatbots, language translation, sentiment analysis,\n",
            " and text summarization.\n",
            "* **Computer Vision:** Used in image recognition, object detection, and facial recognition.\n",
            "* **Education:** Personalized learning platforms, automated grading systems.\n",
            "* **Security:** Cybersecurity threat detection and prevention.\n",
            "* **Agriculture:** Precision farming, crop monitoring, and yield prediction.\n",
            "\n",
            "\n",
            "This\n",
            " is not an exhaustive list, but it provides a broad overview of the diverse applications of AI.  New applications are constantly emerging as the technology continues to advance.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "message_list = [HumanMessage(content=\"hi\", name = \"arman\"),\n",
        "                AIMessage(content=\"AI is a tool for building helpful, accurate, and unbiased AI systems.\", name = \"AI Assistant\"),\n",
        "                HumanMessage(content=\"What are some AI applications?\", name = \"arman\")]\n",
        "llm.invoke(message_list).content\n",
        "for chunk in llm.stream(message_list):\n",
        "    print(chunk.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "KKnOnfj3YZYT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKnOnfj3YZYT",
        "outputId": "f85f98a2-83c0-4c48-ade8-0e32da40c894"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='The 2024 US presidential election has not yet happened.  The election will be held in November 2024.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-2c40876a-e786-4b7b-ad23-4d600ba76665-0', usage_metadata={'input_tokens': 13, 'output_tokens': 29, 'total_tokens': 42, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result  = llm.invoke(\"Who won 2024 US presidential ellection?\")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28450d1b",
      "metadata": {
        "id": "28450d1b"
      },
      "source": [
        "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
        "\n",
        "* `stream`: stream back chunks of the response\n",
        "* `invoke`: call the chain on an input\n",
        "\n",
        "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b1280e1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1280e1b",
        "outputId": "ad53b729-941a-4da4-ac3b-d1a683c8661f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='There' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 39, 'output_tokens': 0, 'total_tokens': 39, 'input_token_details': {'cache_read': 0}}\n",
            "content=' are several ways to learn LangChain, depending on your learning style and prior experience' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=':\\n\\n**1. Official Documentation:** The best place to start is the official' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=' LangChain documentation.  It\\'s well-structured and provides comprehensive tutorials and examples.  Look for their \"Getting Started\" guides and work your way through' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=' the examples.\\n\\n**2. Tutorials and Blog Posts:** Many tutorials and blog posts are available online that cover various aspects of LangChain. Search for \"Lang' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content='Chain tutorial\" or \"LangChain example\" on Google, YouTube, and Medium.  Look for tutorials that focus on specific use cases that interest you, such as building a chatbot or a question-answering system.\\n\\n**3.' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=' GitHub Repository:** Explore the LangChain GitHub repository.  You can find the source code, contribute to the project, and see how different components are implemented.  Reading the code can be a great way to deepen your understanding.\\n\\n**4' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content='. Example Projects:**  The LangChain documentation and GitHub repository contain many example projects.  Start by running and modifying these examples to understand how different parts of the framework work together.  Try to break them and see what happens – this is a great way to learn.\\n\\n**5. Community and Forums:** Engage with' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=\" the LangChain community.  Ask questions on forums like Stack Overflow or join the LangChain Discord server (if one exists).  This is a great way to get help and learn from others' experiences.\\n\\n**6. Courses (Future Possibility):** While there aren't many dedicated LangChain courses yet, as\" additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=' the framework is relatively new, you might find relevant courses on broader topics like large language models (LLMs) or building AI applications.  These courses might include sections on LangChain or provide a foundation that makes learning LangChain easier.\\n\\n\\n**To get started quickly, I recommend:**\\n\\n* **Familiarize yourself with' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=' the basic concepts:** Understand what LLMs are and how they work.  Having a basic understanding of Python programming is also essential.\\n* **Follow the official \"Getting Started\" guide:** This will walk you through setting up LangChain and building a simple application.\\n* **Choose a specific project:**  Instead of' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=' trying to learn everything at once, focus on a particular application you want to build (e.g., a chatbot, a summarizer, a question-answering system).  This will give you a clear goal and make the learning process more engaging.\\n\\n\\nRemember to be patient and persistent.  LangChain is a' additional_kwargs={} response_metadata={'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
            "content=\" powerful framework, but it takes time and practice to master.  Start with the basics, gradually increase the complexity of your projects, and don't hesitate to ask for help when you need it.\\n\" additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'safety_ratings': []} id='run-a456fc4a-660c-4bb5-836e-279f6e90796e' usage_metadata={'input_tokens': 0, 'output_tokens': 554, 'total_tokens': 554, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        " \n",
        "messages = [\n",
        "    HumanMessage(content=\"Hi\", name=\"Human Student\"),\n",
        "    AIMessage(content='Hi! How can I help you today? \\n', name=\"AI Assistant\"),\n",
        "    HumanMessage(content=\"What is LangChain?\", name=\"Human Student\"),\n",
        "    AIMessage(content='LangChain is a framework for developing applications powered by language models.', name=\"AI Assistant\"),\n",
        "    HumanMessage(content=\"How can I learn\", name=\"Human Student\"),\n",
        "    ]\n",
        "\n",
        "# Invoke the model with a list of messages\n",
        "llm.invoke(messages)\n",
        "for chunk in llm.stream(messages):\n",
        "    print(chunk.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cac73e4c",
      "metadata": {
        "id": "cac73e4c"
      },
      "source": [
        "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "582c0e5a",
      "metadata": {
        "id": "582c0e5a"
      },
      "source": [
        "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks.\n",
        "\n",
        "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad0069a",
      "metadata": {
        "id": "3ad0069a"
      },
      "source": [
        "## Search Tools\n",
        "\n",
        "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "52d69da9",
      "metadata": {
        "id": "52d69da9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        " \n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(max_results=1)\n",
        "search_docs = tavily_search.invoke(\"Who won the 2024 pakistan election and become the priminester?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "JWzZ6zAvb2Fv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWzZ6zAvb2Fv",
        "outputId": "5d7a0e6d-e90f-4cf0-cd5f-82dd5af2a1b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'url': 'https://www.voanews.com/a/lawmakers-elect-shehbaz-sharif-as-pakistan-s-new-premier-/7511722.html',\n",
              "  'content': \"Pakistan Elects Shehbaz Sharif as New Prime Minister Africa The Americas East Asia Europe Middle East South & Central Asia Pakistan Elects Shehbaz Sharif as New Prime Minister This handout photograph taken and released on March 3, 2024 by the Pakistan National Assembly, shows Pakistan's newly-elected Prime Minister Shehbaz Sharif (2R) addresses the Parliament in Islamabad. ISLAMABAD —\\xa0Pakistan’s newly elected National Assembly chose Shehbaz Sharif as the country’s new prime minister Sunday following a February general election that was marred by widespread rigging allegations. The declaration was met with loud protests from lawmakers, loyal to Khan, who persisted in alleging that the February 8 national elections were heavily rigged to support pro-military parties, including Sharif’s Pakistan Muslim League-Nawaz, or PML-N.\"}]"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search_docs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
