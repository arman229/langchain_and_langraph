{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Memory\n",
    "\n",
    "## Review\n",
    "\n",
    "[Memory](https://pmc.ncbi.nlm.nih.gov/articles/PMC10410470/) is a cognitive function that allows people to store, retrieve, and use information to understand their present and future.\n",
    "\n",
    "There are [various long-term memory types](https://langchain-ai.github.io/langgraph/concepts/memory/#memory) that can be used in AI applications.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Here, we'll introduce the [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) as a way to save and retrieve long-term memories.\n",
    "\n",
    "We'll build a chatbot that uses both `short-term (within-thread)` and `long-term (across-thread)` memory.\n",
    "\n",
    "We'll focus on long-term [semantic memory](https://langchain-ai.github.io/langgraph/concepts/memory/#semantic-memory), which will be facts about the user.\n",
    "\n",
    "These long-term memories will be used to create a personalized chatbot that can remember facts about the user.\n",
    "\n",
    "It will save memory [\"in the hot path\"](https://langchain-ai.github.io/langgraph/concepts/memory/#writing-memories), as the user is chatting with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_google_genai langgraph langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the LangGraph Store\n",
    "\n",
    "The [LangGraph Memory Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) provides a way to store and retrieve information *across threads* in LangGraph.\n",
    "\n",
    "This is an  [open source base class](https://blog.langchain.dev/launching-long-term-memory-support-in-langgraph/) for persistent `key-value` stores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When storing objects (e.g., memories) in the [Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore), we provide:\n",
    "\n",
    "- The `namespace` for the object, a tuple (similar to directories)\n",
    "- the object `key` (similar to filenames)\n",
    "- the object `value` (similar to file contents)\n",
    "\n",
    "We use the [put](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.put) method to save an object to the store by `namespace` and `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "memory_store = InMemoryStore()\n",
    "user_id = '1'\n",
    "session_id = str(uuid.uuid4())\n",
    "name_space = (user_id,'memory_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id: 1\n",
      "session_id: 871b94ae-09f4-4e74-b2c8-14d3286e80e9\n",
      "name_space:('1', 'memory_agent')\n"
     ]
    }
   ],
   "source": [
    "print(f'user_id: {user_id}')\n",
    "print(f'session_id: {session_id}')\n",
    "print(f'name_space:{name_space}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = {'name':'Arman','age':23,'profile':'I have completed Bachelor\\'s degree in Mathematics. Now i want to learn Agentic AI'}\n",
    "memory_store.put(name_space,session_id,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid.uuid4())\n",
    "value = {'name':'Arman','age':23,'profile':'I have completed Bachelor\\'s degree in Mathematics. Now i want to learn Agentic AI','teacher':'My best teacher is Sir Zia Khan'}\n",
    "memory_store.put(name_space,session_id,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [search](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.search) to retrieve objects from the store by `namespace`.\n",
    "\n",
    "This returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Item(namespace=['1', 'memory_agent'], key='871b94ae-09f4-4e74-b2c8-14d3286e80e9', value={'name': 'Arman', 'age': 23, 'profile': \"I have completed Bachelor's degree in Mathematics. Now i want to learn Agentic AI\"}, created_at='2025-02-17T07:37:48.179092+00:00', updated_at='2025-02-17T07:37:48.179092+00:00', score=None), Item(namespace=['1', 'memory_agent'], key='945e94b4-9684-4161-967b-1d3521dd726d', value={'name': 'Arman', 'age': 23, 'profile': \"I have completed Bachelor's degree in Mathematics. Now i want to learn Agentic AI\", 'teacher': 'My best teacher is Sir Zia Khan'}, created_at='2025-02-17T07:37:49.328436+00:00', updated_at='2025-02-17T07:37:49.328436+00:00', score=None)]\n"
     ]
    }
   ],
   "source": [
    "search_memory = memory_store.search(name_space)\n",
    "print(search_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use [get](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore.get) to retrieve an object by `namespace` and `key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "get_memory = memory_store.get(name_space,'9697e0cd-92b3-47f6-9159-7a63019952a1')\n",
    "print(get_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with long-term memory\n",
    "\n",
    "We want a chatbot that [has two types of memory](https://docs.google.com/presentation/d/181mvjlgsnxudQI6S3ritg9sooNyu4AcLLFH1UK0kIuk/edit#slide=id.g30eb3c8cf10_0_156):\n",
    "\n",
    "1. `Short-term (within-thread) memory`: Chatbot can persist conversational history and / or allow interruptions in a chat session.\n",
    "2. `Long-term (cross-thread) memory`: Chatbot can remember information about a specific user *across all chat sessions*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded from .env file.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in the .env file.\")\n",
    "\n",
    "print(\"API key loaded from .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `short-term memory`, we'll use a [checkpointer](https://langchain-ai.github.io/langgraph/concepts/persistence/#checkpointer-libraries).\n",
    "\n",
    "See Module 2 and our [conceptual docs](https://langchain-ai.github.io/langgraph/concepts/persistence/) for more on checkpointers, but in summary:\n",
    "\n",
    "* They write the graph state at each step to a thread.\n",
    "* They persist the chat history in the thread.\n",
    "* They allow the graph to be interrupted and / or resumed from any step in the thread.\n",
    "\n",
    "And, for `long-term memory`, we'll use the [LangGraph Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore) as introduced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash',api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chat history will be saved to short-term memory using the checkpointer.\n",
    "\n",
    "The chatbot will reflect on the chat history.\n",
    "\n",
    "It will then create and save a memory to the [LangGraph Store](https://langchain-ai.github.io/langgraph/reference/store/#langgraph.store.base.BaseStore).\n",
    "\n",
    "This memory is accessible in future chat sessions to personalize the chatbot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user.\n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "def call_model(state:MessagesState,config:RunnableConfig,store:BaseStore):\n",
    "  user_id = config[\"configurable\"][\"user_id\"]\n",
    "  namespace = (\"memory\", user_id) \n",
    "  existing_memory = store.get(namespace, 'user_memory')\n",
    "  if existing_memory:\n",
    "     existing_memory_content = existing_memory.value.get('memory')\n",
    "  else:\n",
    "    existing_memory_content = \"No existing memory found.\"\n",
    "  sys_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    " \n",
    "  messages = [SystemMessage(content=sys_msg)] + state[\"messages\"]\n",
    "\n",
    "  resp = model.invoke(messages)\n",
    "  return {\"messages\":resp}\n",
    "\n",
    "\n",
    "\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\"You are collecting information about\n",
    "the user to personalize your responses.\n",
    "\n",
    "CURRENT USER INFORMATION:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below, please update the user information:\"\"\"\n",
    "def call_summary(state:MessagesState,config:RunnableConfig,store:BaseStore):\n",
    "  user_id = config[\"configurable\"][\"user_id\"]\n",
    "  namespace = (\"memory\", user_id) \n",
    "  existing_memory = store.get(namespace, 'user_memory')\n",
    "  if existing_memory:\n",
    "     existing_memory_content = existing_memory.value.get('memory')\n",
    "  else:\n",
    "    existing_memory_content = \"No existing memory found.\"\n",
    "  sys_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "  messages = [SystemMessage(content=sys_msg) ]+ state[\"messages\"]\n",
    "  resp = model.invoke(messages)  \n",
    "  store.put(namespace, 'user_memory', {\"memory\": resp.content})\n",
    "\n",
    "\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node('call_model',call_model)\n",
    "graph.add_node('call_summary',call_summary)\n",
    "\n",
    "graph.add_edge(START,'call_model') \n",
    "graph.add_edge('call_model','call_summary')\n",
    "graph.add_edge('call_summary',END)\n",
    "\n",
    "short_term_memory = MemorySaver()\n",
    "long_term_memory = InMemoryStore()\n",
    "compiled_graph = graph.compile(checkpointer=short_term_memory,store=long_term_memory) \n",
    "\n",
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we interact with the chatbot, we supply two things:\n",
    "\n",
    "1. `Short-term (within-thread) memory`: A `thread ID` for persisting the chat history.\n",
    "2. `Long-term (cross-thread) memory`: A `user ID` to namespace long-term memories to the user.\n",
    "\n",
    "Let's see how these work together in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is arman\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Arman, it's nice to meet you!  I'll remember that for our future conversations.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}} \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is arman\")] \n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like programming\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Arman!  Programming is a fascinating and rewarding field. What kind of programming are you interested in?  Do you have a favorite language or area of focus (e.g., web development, game development, data science)?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}} \n",
    "input_messages = [HumanMessage(content=\"I like programming\")] \n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the `MemorySaver` checkpointer for within-thread memory.\n",
    "\n",
    "This saves the chat history to the thread.\n",
    "\n",
    "We can look at the chat history saved to the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is arman\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Arman, it's nice to meet you!  I'll remember that for our future conversations.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like programming\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Arman!  Programming is a fascinating and rewarding field. What kind of programming are you interested in?  Do you have a favorite language or area of focus (e.g., web development, game development, data science)?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "state = compiled_graph.get_state(thread).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we compiled the graph with our the store:\n",
    "\n",
    "```python\n",
    "across_thread_memory = InMemoryStore()\n",
    "```\n",
    "\n",
    "And, we added a node to the graph (`write_memory`) that reflects on the chat history and saves a memory to the store.\n",
    "\n",
    "We can to see if the memory was saved to the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memory', '1'], 'key': 'user_memory', 'value': {'memory': \"Here's an updated summary of what I know about you:\\n\\n* Name: Arman\\n* Likes: Programming\\n\\n\"}, 'created_at': '2025-02-17T07:38:05.931736+00:00', 'updated_at': '2025-02-17T07:38:05.931736+00:00'}\n"
     ]
    }
   ],
   "source": [
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "get_memory = long_term_memory.get(namespace,'user_memory')\n",
    "if get_memory is not None:\n",
    "    print(get_memory.dict())   \n",
    "else:\n",
    "    print(\"No memory found for this user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No memory found for this user.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_id = \"12\"\n",
    "namespace = (\"memory\", user_id)\n",
    "get_memory = long_term_memory.get(namespace,'user_memory')\n",
    "if get_memory is not None:\n",
    "    print(get_memory.dict())   \n",
    "else:\n",
    "    print(\"No memory found for this user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's kick off a *new thread* with the *same user ID*.\n",
    "\n",
    "We should see that the chatbot remembered the user's profile and used it to personalize the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi! What do you know about me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Arman!  I know that you like programming.  Is there anything else I should know about you?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"12\", \"user_id\": \"1\"}} \n",
    "input_messages = [HumanMessage(content=\"Hi! What do you know about me?\")] \n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I am from pakistan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to know, Arman!  So you're a programmer from Pakistan.  Is there anything else you'd like to share, or any questions you have for me?\n"
     ]
    }
   ],
   "source": [
    " \n",
    "input_messages = [HumanMessage(content=\"I am from pakistan\")] \n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memory', '1'], 'key': 'user_memory', 'value': {'memory': \"Here's my updated information about you:\\n\\n* Name: Arman\\n* Likes: Programming\\n* Location: Pakistan\\n\"}, 'created_at': '2025-02-17T07:38:27.245643+00:00', 'updated_at': '2025-02-17T07:38:27.245643+00:00'}\n"
     ]
    }
   ],
   "source": [
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "get_memory = long_term_memory.get(namespace,'user_memory')\n",
    "if get_memory is not None:\n",
    "    print(get_memory.dict())   \n",
    "else:\n",
    "    print(\"No memory found for this user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing traces in LangSmith\n",
    "\n",
    "We can see that the memories are retrieved from the store and supplied as part of the system prompt, as expected:\n",
    "\n",
    "https://smith.langchain.com/public/10268d64-82ff-434e-ac02-4afa5cc15432/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
