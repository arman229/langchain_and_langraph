{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.colab import userdata\n",
    "\n",
    "os.environ['GEMINI_API_KEY'] =  userdata.get('GEMINI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] =  userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq crewai crewai-tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "llm1 = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    ")\n",
    "\n",
    "llm1.call(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'userdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m google_embedder = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mprovider\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgoogle\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      4\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmodels/text-embedding-004\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43muserdata\u001b[49m.get(\u001b[33m'\u001b[39m\u001b[33mGEMINI_API_KEY\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      6\u001b[39m          }\n\u001b[32m      7\u001b[39m }\n",
      "\u001b[31mNameError\u001b[39m: name 'userdata' is not defined"
     ]
    }
   ],
   "source": [
    "google_embedder = {\n",
    "    \"provider\": \"google\",\n",
    "    \"config\": {\n",
    "         \"model\": \"models/text-embedding-004\",\n",
    "         \"api_key\": userdata.get('GEMINI_API_KEY'),\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35m Flow started with ID: 12c37507-02d5-49c4-8792-51c662d459ce\u001b[00m\n",
      "step1\n",
      "step2\n"
     ]
    }
   ],
   "source": [
    "from crewai.flow.flow import Flow, start, listen\n",
    "\n",
    "\n",
    "class MyFlow(Flow):\n",
    "\n",
    "  @start()\n",
    "  def function1(self):\n",
    "    print(\"step1\")\n",
    "\n",
    "  @listen(function1)\n",
    "  def function2(self):\n",
    "    print(\"step2\")\n",
    "\n",
    "obj = MyFlow()\n",
    "obj.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os \n",
    "api_key=os.getenv('GEMINI_API_KEY'),\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully\")\n",
    "else:\n",
    "    print(\"API key not loaded\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New Delhi**.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from crewai import LLM\n",
    "\n",
    "llm1 = LLM(model=\"gemini/gemini-2.0-flash\")\n",
    "\n",
    "llm1.call(\"What is the capital of india?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_embedder = {\n",
    "    \"provider\": \"google\",\n",
    "    \"config\": {\n",
    "         \"model\": \"models/text-embedding-004\",\n",
    "         \"api_key\": api_key,\n",
    "         }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import os\n",
    "from crewai import LLM \n",
    "\n",
    " \n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource \n",
    "\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "MODEL = os.environ.get(\"MODEL\", \"gemini/gemini-1.5-flash\")\n",
    "\n",
    "gemini_llm = LLM(\n",
    "    model=MODEL,\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0,\n",
    ")\n",
    "google_embedder = {\n",
    "    \"provider\": \"google\",\n",
    "    \"config\": {\n",
    "        \"model\": \"models/embedding-001\",\n",
    "        \"api_key\": GEMINI_API_KEY,\n",
    "    },\n",
    "}\n",
    "content = \"Users name is John. He is 30 years old and lives in San Francisco.\"\n",
    "string_source = StringKnowledgeSource(\n",
    "    content=content,\n",
    ")\n",
    " \n",
    "agent = Agent(\n",
    "    role=\"About User\",\n",
    "    goal=\"You know everything about the user.\",\n",
    "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=gemini_llm,\n",
    ")\n",
    "task = Task(\n",
    "    description=\"Answer the following questions about the user: {question}\",\n",
    "    expected_output=\"An answer to the question.\",\n",
    "    agent=agent,\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    "    process=Process.sequential,\n",
    "    knowledge_sources=[string_source],  \n",
    "    embedder=google_embedder,\n",
    ")\n",
    "\n",
    "result = crew.kickoff(\n",
    "    inputs={\"question\": \"What city does John live in and how old is he?\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m \n",
      "[2025-03-09 08:47:40][WARNING]: Failed to init knowledge: Please provide an OpenAI API key. You can get one at https://platform.openai.com/account/api-keys\u001b[00m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     33\u001b[39m task = Task(\n\u001b[32m     34\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mAnswer the following questions about the user: \u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     35\u001b[39m     expected_output=\u001b[33m\"\u001b[39m\u001b[33mAn answer to the question.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     agent=agent,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m crew = Crew(\n\u001b[32m     40\u001b[39m     memory=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     41\u001b[39m     agents=[agent],\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m result = \u001b[43mcrew\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat city muhammad qasim live?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\crew.py:558\u001b[39m, in \u001b[36mCrew.kickoff\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    555\u001b[39m metrics: List[UsageMetrics] = []\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.sequential:\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process == Process.hierarchical:\n\u001b[32m    560\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._run_hierarchical_process()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\crew.py:665\u001b[39m, in \u001b[36mCrew._run_sequential_process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> CrewOutput:\n\u001b[32m    664\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\crew.py:767\u001b[39m, in \u001b[36mCrew._execute_tasks\u001b[39m\u001b[34m(self, tasks, start_index, was_replayed)\u001b[39m\n\u001b[32m    764\u001b[39m     futures.clear()\n\u001b[32m    766\u001b[39m context = \u001b[38;5;28mself\u001b[39m._get_context(task, task_outputs)\n\u001b[32m--> \u001b[39m\u001b[32m767\u001b[39m task_output = \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    768\u001b[39m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    770\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    771\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    772\u001b[39m task_outputs = [task_output]\n\u001b[32m    773\u001b[39m \u001b[38;5;28mself\u001b[39m._process_task_result(task, task_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\task.py:302\u001b[39m, in \u001b[36mTask.execute_sync\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mexecute_sync\u001b[39m(\n\u001b[32m    296\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    297\u001b[39m     agent: Optional[BaseAgent] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    298\u001b[39m     context: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m     tools: Optional[List[BaseTool]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    300\u001b[39m ) -> TaskOutput:\n\u001b[32m    301\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\task.py:366\u001b[39m, in \u001b[36mTask._execute_core\u001b[39m\u001b[34m(self, agent, context, tools)\u001b[39m\n\u001b[32m    362\u001b[39m tools = tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    364\u001b[39m \u001b[38;5;28mself\u001b[39m.processed_by_agents.add(agent.role)\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m result = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m pydantic_output, json_output = \u001b[38;5;28mself\u001b[39m._export_output(result)\n\u001b[32m    373\u001b[39m task_output = TaskOutput(\n\u001b[32m    374\u001b[39m     name=\u001b[38;5;28mself\u001b[39m.name,\n\u001b[32m    375\u001b[39m     description=\u001b[38;5;28mself\u001b[39m.description,\n\u001b[32m   (...)\u001b[39m\u001b[32m    381\u001b[39m     output_format=\u001b[38;5;28mself\u001b[39m._get_output_format(),\n\u001b[32m    382\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\agent.py:219\u001b[39m, in \u001b[36mAgent.execute_task\u001b[39m\u001b[34m(self, task, context, tools)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.crew \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.crew.memory:\n\u001b[32m    212\u001b[39m     contextual_memory = ContextualMemory(\n\u001b[32m    213\u001b[39m         \u001b[38;5;28mself\u001b[39m.crew.memory_config,\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m.crew._short_term_memory,\n\u001b[32m   (...)\u001b[39m\u001b[32m    217\u001b[39m         \u001b[38;5;28mself\u001b[39m.crew._user_memory,\n\u001b[32m    218\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     memory = \u001b[43mcontextual_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_context_for_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m memory.strip() != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    221\u001b[39m         task_prompt += \u001b[38;5;28mself\u001b[39m.i18n.slice(\u001b[33m\"\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m\"\u001b[39m).format(memory=memory)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\memory\\contextual\\contextual_memory.py:36\u001b[39m, in \u001b[36mContextualMemory.build_context_for_task\u001b[39m\u001b[34m(self, task, context)\u001b[39m\n\u001b[32m     34\u001b[39m context = []\n\u001b[32m     35\u001b[39m context.append(\u001b[38;5;28mself\u001b[39m._fetch_ltm_context(task.description))\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m context.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_stm_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     37\u001b[39m context.append(\u001b[38;5;28mself\u001b[39m._fetch_entity_context(query))\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.memory_provider == \u001b[33m\"\u001b[39m\u001b[33mmem0\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\memory\\contextual\\contextual_memory.py:47\u001b[39m, in \u001b[36mContextualMemory._fetch_stm_context\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fetch_stm_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, query) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     43\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[33;03m    Fetches recent relevant insights from STM related to the task's description and expected_output,\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m    formatted as bullet points.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     stm_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     formatted_results = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m     49\u001b[39m         [\n\u001b[32m     50\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mmemory\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m.memory_provider\u001b[38;5;250m \u001b[39m==\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmem0\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39mresult[\u001b[33m'\u001b[39m\u001b[33mcontext\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     51\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m stm_results\n\u001b[32m     52\u001b[39m         ]\n\u001b[32m     53\u001b[39m     )\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecent Insights:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mformatted_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stm_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\memory\\short_term\\short_term_memory.py:62\u001b[39m, in \u001b[36mShortTermMemory.search\u001b[39m\u001b[34m(self, query, limit, score_threshold)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch\u001b[39m(\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     58\u001b[39m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     59\u001b[39m     limit: \u001b[38;5;28mint\u001b[39m = \u001b[32m3\u001b[39m,\n\u001b[32m     60\u001b[39m     score_threshold: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.35\u001b[39m,\n\u001b[32m     61\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscore_threshold\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\crewai\\memory\\storage\\rag_storage.py:123\u001b[39m, in \u001b[36mRAGStorage.search\u001b[39m\u001b[34m(self, query, limit, filter, score_threshold)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m suppress_logging():\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     results = []\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m])):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:211\u001b[39m, in \u001b[36mCollection.query\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\n\u001b[32m    169\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    170\u001b[39m     query_embeddings: Optional[\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m     ],\n\u001b[32m    187\u001b[39m ) -> QueryResult:\n\u001b[32m    188\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the n_results nearest neighbor embeddings for provided query_embeddings or query_texts.\u001b[39;00m\n\u001b[32m    189\u001b[39m \n\u001b[32m    190\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    208\u001b[39m \n\u001b[32m    209\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     query_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_query_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_images\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_uris\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_uris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     query_results = \u001b[38;5;28mself\u001b[39m._client._query(\n\u001b[32m    223\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    224\u001b[39m         query_embeddings=query_request[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    230\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    231\u001b[39m     )\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform_query_response(\n\u001b[32m    234\u001b[39m         response=query_results, include=query_request[\u001b[33m\"\u001b[39m\u001b[33minclude\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    235\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:90\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     92\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:301\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_query_request\u001b[39m\u001b[34m(self, query_embeddings, query_texts, query_images, query_uris, n_results, where, where_document, include)\u001b[39m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m query_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    300\u001b[39m     validate_record_set_for_embedding(record_set=query_records)\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m     request_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    303\u001b[39m     request_embeddings = query_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:526\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields)\u001b[39m\n\u001b[32m    522\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed(\n\u001b[32m    523\u001b[39m                 \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m._data_loader(uris=cast(URIs, record_set[field]))  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    524\u001b[39m             )\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    528\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:539\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    536\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must provide an embedding function to compute embeddings.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    537\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.trychroma.com/guides/embeddings\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    538\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\api\\types.py:466\u001b[39m, in \u001b[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) -> Embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\chromadb\\utils\\embedding_functions\\google_embedding_function.py:74\u001b[39m, in \u001b[36mGoogleGenerativeAiEmbeddingFunction.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Documents) -> Embeddings:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_genai\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_task_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_task_title\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n\u001b[32m     81\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\embedding.py:213\u001b[39m, in \u001b[36membed_content\u001b[39m\u001b[34m(model, content, task_type, title, output_dimensionality, client, request_options)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    206\u001b[39m     embedding_request = protos.EmbedContentRequest(\n\u001b[32m    207\u001b[39m         model=model,\n\u001b[32m    208\u001b[39m         content=content_types.to_content(content),\n\u001b[32m   (...)\u001b[39m\u001b[32m    211\u001b[39m         output_dimensionality=output_dimensionality,\n\u001b[32m    212\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     embedding_response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m        \u001b[49m\u001b[43membedding_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m     embedding_dict = \u001b[38;5;28mtype\u001b[39m(embedding_response).to_dict(embedding_response)\n\u001b[32m    218\u001b[39m     embedding_dict[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m] = embedding_dict[\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:1252\u001b[39m, in \u001b[36mGenerativeServiceClient.embed_content\u001b[39m\u001b[34m(self, request, model, content, retry, timeout, metadata)\u001b[39m\n\u001b[32m   1249\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m   1251\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m   1260\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[32m    118\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mself\u001b[39m._timeout - time_since_first_attempt)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\grpc\\_channel.py:1178\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1168\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1173\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1174\u001b[39m ) -> Any:\n\u001b[32m   1175\u001b[39m     (\n\u001b[32m   1176\u001b[39m         state,\n\u001b[32m   1177\u001b[39m         call,\n\u001b[32m-> \u001b[39m\u001b[32m1178\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\grpc\\_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
    "google_embedder = {\n",
    "    \"provider\": \"google\",\n",
    "    \"config\": {\n",
    "         \"model\": \"models/text-embedding-004\",\n",
    "         \"api_key\":  api_key,\n",
    "         }\n",
    "}\n",
    "from crewai import LLM\n",
    "\n",
    "llm1 = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash\",\n",
    ")\n",
    "\n",
    "llm1.call(\"What is the capital of France?\")\n",
    "# Create a knowledge source\n",
    "content = \"Users name is Muhammad Qasim. He is 30 years old and lives in Karchi, Pakistan. He is working as Chief Data Scientist at CancerClarity LLC\"\n",
    "string_source = StringKnowledgeSource(\n",
    "    content=content,\n",
    ")\n",
    "\n",
    "\n",
    "# Create an agent with the knowledge store\n",
    "agent = Agent(\n",
    "    role=\"About User\",\n",
    "    goal=\"You know everything about the user.\",\n",
    "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm1,\n",
    ")\n",
    "task = Task(\n",
    "    description=\"Answer the following questions about the user: {question}\",\n",
    "    expected_output=\"An answer to the question.\",\n",
    "    agent=agent,\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    memory=True,\n",
    "    agents=[agent],\n",
    "    tasks=[task],\n",
    "    verbose=True,\n",
    "    process=Process.sequential,\n",
    "    knowledge_sources=[string_source], # Enable knowledge by adding the sources here. You can also add more sources to the sources list.\n",
    "    embedder=google_embedder\n",
    "\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\"question\": \"What city muhammad qasim live?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92myou will be responsible for all PIAIC relevant operations, student query 'I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.' you must be know how to answer his question based on final context\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mPiaic student card generator\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"student_name\\\": \\\"Muhammad Qasim\\\", \\\"student_roll_no\\\": 100}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "PIAIC student card\n",
      "student name: Muhammad Qasim\n",
      "student roll no: 100\n",
      "Pakistan zindabd!\n",
      "        \u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mPIAIC manager\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "PIAIC student card\n",
      "student name: Muhammad Qasim\n",
      "student roll no: 100\n",
      "Pakistan zindabd!\u001b[00m\n",
      "\n",
      "\n",
      "PIAIC student card\n",
      "student name: Muhammad Qasim\n",
      "student roll no: 100\n",
      "Pakistan zindabd!\n"
     ]
    }
   ],
   "source": [
    "from crewai.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type\n",
    "from crewai import Agent, Task, Crew\n",
    "\n",
    "\n",
    "class MyToolInput(BaseModel):\n",
    "    \"\"\"Input schema for MyCustomTool.\"\"\"\n",
    "    student_name: str = Field(..., description=\"Student name\")\n",
    "    student_roll_no : int = Field(..., description=\"student id\")\n",
    "\n",
    "class PiaicStudentCard(BaseTool):\n",
    "    name: str = \"Piaic student card generator\"\n",
    "    description: str = \"this function will create Piaic student card\"\n",
    "    args_schema: Type[BaseModel] = MyToolInput\n",
    "\n",
    "    def _run(self, student_name: str, student_roll_no: int ) -> str:\n",
    "        # Your tool's logic here\n",
    "        return f\"\"\"PIAIC student card\n",
    "student name: {student_name}\n",
    "student roll no: {student_roll_no}\n",
    "Pakistan zindabd!\n",
    "        \"\"\"\n",
    " \n",
    "from crewai.tools import tool\n",
    "@tool(\"PIAIC fee update\")\n",
    "def my_tool(roll_no: int) -> dict | str:\n",
    "    \"\"\"this function search piaic student fee updates, it will required roll no of PIAIC student\"\"\"\n",
    "    #database\n",
    "\n",
    "    data = {100:'paid',\n",
    "         200:'unpaid'}\n",
    "\n",
    "\n",
    "    status = data.get(roll_no)\n",
    "\n",
    "    if status:\n",
    "      return {\"status\": status}\n",
    "    else:\n",
    "      return \"student not found\"\n",
    "\n",
    "card = PiaicStudentCard()\n",
    "\n",
    "\n",
    "piaic_manager = Agent(\n",
    "    role=\"PIAIC manager\",\n",
    "    goal = \"Manage all quries regarding PIAIC and you will use only relevant tools for student query\",\n",
    "    backstory=\"\"\"You are a master at understanding people and their preferences.\"\"\",\n",
    "    tools=[card, my_tool],\n",
    "    verbose=True,\n",
    "    llm=llm1\n",
    ")\n",
    "\n",
    "piaic_card_creator = Task(\n",
    "    description=\"you will be responsible for all PIAIC relevant operations, student query '{query}' you must be know how to answer his question based on final context\",\n",
    "    expected_output=\"final query answer only\",\n",
    "    agent=piaic_manager\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[piaic_manager],\n",
    "    tasks=[piaic_card_creator],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = crew.kickoff(inputs={\n",
    "    \"query\":\"I'm PIAIC student my name is Muhammad Qasim and my roll number is 100, can you create my student card.\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.17976661 5.08626355 1.8641332  5.379051   4.23368959 1.67236517\n",
      " 3.20823103 3.40999136 1.69758227 5.37521783 1.05011251 2.90688717\n",
      " 5.14415336 0.44527749 4.05958295 3.34860523 4.0927961  1.63728841\n",
      " 5.18115848 4.34869583 1.32772507 2.02439074 0.68346852 2.50226314\n",
      " 3.06441464 0.60461867 3.72517938 0.58820872 1.64695017 3.01011362\n",
      " 5.40357436 3.12447677 4.78946705 2.46048628 4.49720015 1.71330144\n",
      " 0.59772826 1.18612388 4.43293021 2.70338044 2.34015927 4.78427119\n",
      " 1.8548719  4.74089338 2.75061946 2.62625263 2.65731019 2.40550944\n",
      " 3.28847841 0.32997232 1.2379398  0.32889031 2.94869455 1.88840946\n",
      " 3.96122781 4.81223798 1.20746704 4.20702462 3.66787836 3.27240668\n",
      " 4.63890502 3.84317231 5.3776806  2.03339333 1.30376138 1.68619178\n",
      " 3.50975211 0.85391921 0.67778525 4.58516165 4.98293033 1.05621504\n",
      " 3.79977983 0.47021244 0.41610756 3.11353386 1.6226643  3.26882398\n",
      " 3.75390416 1.03124432 3.72760506 2.46418307 1.71503168 1.57632281\n",
      " 5.59042901 5.36392664 0.82883076 3.35931404 1.16708803 5.45059219\n",
      " 1.83502178 3.75502755 5.41768468 5.26792304 3.60873084 3.04287242\n",
      " 3.9594016  1.27297077 1.47286907 5.19946319 2.56822435 4.3576286\n",
      " 1.27894261 0.64719171 2.79997814 5.00767193 1.56909841 2.18355846\n",
      " 1.35443479 3.92366432 5.10580602 1.98783309 1.77193423 2.28296593\n",
      " 3.35435276 1.9509576  4.25662628 2.97748682 1.74986065 2.18428548\n",
      " 3.00003798 1.3563031  3.40991835 5.57965658 2.21148113 2.28285169\n",
      " 4.6079576  4.42142981 5.10061289 4.88808961 1.42839392 1.33101965\n",
      " 1.84455412 0.51563802 4.54819675 2.63664127 3.10174285 4.68197607\n",
      " 5.40994894 2.50919735]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "x = numpy.random.uniform(0.1,5.6,140)\n",
    "plt.hist(x,10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (global-venv)",
   "language": "python",
   "name": "global-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
